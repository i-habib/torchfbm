
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://i-habib.github.io/torchfbm-docs/api/">
      
      
        <link rel="prev" href="..">
      
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>API Reference - TorchFBM Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#api-reference" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="TorchFBM Documentation" class="md-header__button md-logo" aria-label="TorchFBM Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            TorchFBM Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API Reference
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="purple"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/i-habib/torchfbm" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
  
    
  
  API Reference

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="TorchFBM Documentation" class="md-nav__button md-logo" aria-label="TorchFBM Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    TorchFBM Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/i-habib/torchfbm" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#generators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generators
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.generators" class="md-nav__link">
    <span class="md-ellipsis">
      
        generators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="generators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators--generate-fbm-path-with-h07" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generate fBm path with H=0.7
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators--generate-fgn-increments" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generate fGn increments
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators.fbm" class="md-nav__link">
    <span class="md-ellipsis">
      
        fbm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators.generate_cholesky" class="md-nav__link">
    <span class="md-ellipsis">
      
        generate_cholesky
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators.generate_davies_harte" class="md-nav__link">
    <span class="md-ellipsis">
      
        generate_davies_harte
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Estimators
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        estimators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="estimators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.estimators.estimate_hurst" class="md-nav__link">
    <span class="md-ellipsis">
      
        estimate_hurst
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dfa" class="md-nav__link">
    <span class="md-ellipsis">
      
        DFA
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.dfa" class="md-nav__link">
    <span class="md-ellipsis">
      
        dfa
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="dfa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.dfa.dfa" class="md-nav__link">
    <span class="md-ellipsis">
      
        dfa
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Analysis
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.covariance_matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
        covariance_matrix
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.plot_acf" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_acf
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.spectral_scaling_factor" class="md-nav__link">
    <span class="md-ellipsis">
      
        spectral_scaling_factor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="spectral_scaling_factor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.spectral_scaling_factor--use-for-spectral-synthesis-fft_coeffs-white_noise-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use for spectral synthesis: fft_coeffs = white_noise * scaling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#processes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Processes
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.processes" class="md-nav__link">
    <span class="md-ellipsis">
      
        processes
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="processes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes--mean-reverting-process-with-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mean-reverting process with memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes--asset-prices-with-long-range-dependence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Asset prices with long-range dependence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_brownian_bridge" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_brownian_bridge
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_brownian_bridge">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_brownian_bridge--bridge-from-0-to-1-with-rough-texture" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bridge from 0 to 1 with rough texture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_ou_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_ou_process
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_ou_process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_ou_process--simulate-interest-rate-with-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Simulate interest rate with memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.geometric_fbm" class="md-nav__link">
    <span class="md-ellipsis">
      
        geometric_fbm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="geometric_fbm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.geometric_fbm--simulate-1-year-of-daily-prices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Simulate 1 year of daily prices
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.multifractal_random_walk" class="md-nav__link">
    <span class="md-ellipsis">
      
        multifractal_random_walk
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="multifractal_random_walk">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.multifractal_random_walk--simulate-returns-with-volatility-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Simulate returns with volatility clustering
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.reflected_fbm" class="md-nav__link">
    <span class="md-ellipsis">
      
        reflected_fbm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="reflected_fbm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.reflected_fbm--exchange-rate-in-a-target-zone" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exchange rate in a target zone
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transforms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Transforms
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.transforms" class="md-nav__link">
    <span class="md-ellipsis">
      
        transforms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="transforms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_diff" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_diff
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_diff">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_diff--x_stationary-should-have-lower-autocorrelation" class="md-nav__link">
    <span class="md-ellipsis">
      
        x_stationary should have lower autocorrelation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_integrate" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_integrate
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_integrate">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_integrate--smooth-has-longer-memory-than-noise" class="md-nav__link">
    <span class="md-ellipsis">
      
        smooth has longer memory than noise
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Layers
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        layers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="layers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear" class="md-nav__link">
    <span class="md-ellipsis">
      
        FBMNoisyLinear
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FBMNoisyLinear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear--replace-standard-linear-in-dqn-for-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Replace standard linear in DQN for exploration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.refresh_noise_stream" class="md-nav__link">
    <span class="md-ellipsis">
      
        refresh_noise_stream
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.reset_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.sample_noise" class="md-nav__link">
    <span class="md-ellipsis">
      
        sample_noise
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalKernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        FractionalKernel
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FractionalKernel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalKernel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalPositionalEmbedding" class="md-nav__link">
    <span class="md-ellipsis">
      
        FractionalPositionalEmbedding
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FractionalPositionalEmbedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalPositionalEmbedding.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.fractional_init_" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_init_
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sde" class="md-nav__link">
    <span class="md-ellipsis">
      
        SDE
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.sde" class="md-nav__link">
    <span class="md-ellipsis">
      
        sde
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="sde">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE" class="md-nav__link">
    <span class="md-ellipsis">
      
        NeuralFSDE
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NeuralFSDE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE--define-drift-and-diffusion-networks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Define drift and diffusion networks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE--create-fsde-with-learnable-hurst-parameter" class="md-nav__link">
    <span class="md-ellipsis">
      
        Create fSDE with learnable Hurst parameter
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE--integrate-from-initial-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Integrate from initial conditions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE.H" class="md-nav__link">
    <span class="md-ellipsis">
      
        H
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Loss Functions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        loss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="loss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.HurstRegularizationLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        HurstRegularizationLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HurstRegularizationLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.HurstRegularizationLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.SpectralConsistencyLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpectralConsistencyLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SpectralConsistencyLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.SpectralConsistencyLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#schedulers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Schedulers
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.schedulers" class="md-nav__link">
    <span class="md-ellipsis">
      
        schedulers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="schedulers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers--smooth-start-rough-end" class="md-nav__link">
    <span class="md-ellipsis">
      
        Smooth start, rough end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers.get_hurst_schedule" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_hurst_schedule
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="get_hurst_schedule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers.get_hurst_schedule--linear-schedule-from-rough-to-smooth" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear schedule from rough to smooth
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers.get_hurst_schedule--cosine-schedule-slower-at-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cosine schedule (slower at endpoints)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Augmentations
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      
        augmentations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="augmentations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        FractionalNoiseAugmentation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FractionalNoiseAugmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation--make-model-robust-to-trending-noise" class="md-nav__link">
    <span class="md-ellipsis">
      
        Make model robust to trending noise
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation--during-training-50-of-samples-get-fgn-added" class="md-nav__link">
    <span class="md-ellipsis">
      
        During training, 50% of samples get fGn added
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation--during-eval-no-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        During eval, no augmentation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#online" class="md-nav__link">
    <span class="md-ellipsis">
      
        Online
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.online" class="md-nav__link">
    <span class="md-ellipsis">
      
        online
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="online">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.online.CachedFGNGenerator" class="md-nav__link">
    <span class="md-ellipsis">
      
        CachedFGNGenerator
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CachedFGNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.online.CachedFGNGenerator--generate-samples-one-at-a-time" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generate samples one at a time
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.online.CachedFGNGenerator.step" class="md-nav__link">
    <span class="md-ellipsis">
      
        step
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reinforcement Learning
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.rl" class="md-nav__link">
    <span class="md-ellipsis">
      
        rl
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="rl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise" class="md-nav__link">
    <span class="md-ellipsis">
      
        FBMActionNoise
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FBMActionNoise">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise--for-stable-baselines3" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Stable Baselines3
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise--for-custom-pytorch-rl" class="md-nav__link">
    <span class="md-ellipsis">
      
        For custom PyTorch RL
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __call__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise.reset" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#utilities" class="md-nav__link">
    <span class="md-ellipsis">
      
        Utilities
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.utils" class="md-nav__link">
    <span class="md-ellipsis">
      
        utils
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.utils.get_cholesky_factor" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_cholesky_factor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.utils.get_fgn_autocovariance" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_fgn_autocovariance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.utils.get_fgn_covariance_matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_fgn_covariance_matrix
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#generators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generators
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.generators" class="md-nav__link">
    <span class="md-ellipsis">
      
        generators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="generators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators--generate-fbm-path-with-h07" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generate fBm path with H=0.7
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators--generate-fgn-increments" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generate fGn increments
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators.fbm" class="md-nav__link">
    <span class="md-ellipsis">
      
        fbm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators.generate_cholesky" class="md-nav__link">
    <span class="md-ellipsis">
      
        generate_cholesky
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.generators.generate_davies_harte" class="md-nav__link">
    <span class="md-ellipsis">
      
        generate_davies_harte
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Estimators
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        estimators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="estimators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.estimators.estimate_hurst" class="md-nav__link">
    <span class="md-ellipsis">
      
        estimate_hurst
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dfa" class="md-nav__link">
    <span class="md-ellipsis">
      
        DFA
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.dfa" class="md-nav__link">
    <span class="md-ellipsis">
      
        dfa
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="dfa">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.dfa.dfa" class="md-nav__link">
    <span class="md-ellipsis">
      
        dfa
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Analysis
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.covariance_matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
        covariance_matrix
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.plot_acf" class="md-nav__link">
    <span class="md-ellipsis">
      
        plot_acf
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.spectral_scaling_factor" class="md-nav__link">
    <span class="md-ellipsis">
      
        spectral_scaling_factor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="spectral_scaling_factor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.analysis.spectral_scaling_factor--use-for-spectral-synthesis-fft_coeffs-white_noise-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Use for spectral synthesis: fft_coeffs = white_noise * scaling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#processes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Processes
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.processes" class="md-nav__link">
    <span class="md-ellipsis">
      
        processes
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="processes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes--mean-reverting-process-with-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mean-reverting process with memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes--asset-prices-with-long-range-dependence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Asset prices with long-range dependence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_brownian_bridge" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_brownian_bridge
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_brownian_bridge">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_brownian_bridge--bridge-from-0-to-1-with-rough-texture" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bridge from 0 to 1 with rough texture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_ou_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_ou_process
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_ou_process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.fractional_ou_process--simulate-interest-rate-with-memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Simulate interest rate with memory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.geometric_fbm" class="md-nav__link">
    <span class="md-ellipsis">
      
        geometric_fbm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="geometric_fbm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.geometric_fbm--simulate-1-year-of-daily-prices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Simulate 1 year of daily prices
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.multifractal_random_walk" class="md-nav__link">
    <span class="md-ellipsis">
      
        multifractal_random_walk
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="multifractal_random_walk">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.multifractal_random_walk--simulate-returns-with-volatility-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Simulate returns with volatility clustering
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.reflected_fbm" class="md-nav__link">
    <span class="md-ellipsis">
      
        reflected_fbm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="reflected_fbm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.processes.reflected_fbm--exchange-rate-in-a-target-zone" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exchange rate in a target zone
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transforms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Transforms
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.transforms" class="md-nav__link">
    <span class="md-ellipsis">
      
        transforms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="transforms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_diff" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_diff
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_diff">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_diff--x_stationary-should-have-lower-autocorrelation" class="md-nav__link">
    <span class="md-ellipsis">
      
        x_stationary should have lower autocorrelation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_integrate" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_integrate
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="fractional_integrate">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.transforms.fractional_integrate--smooth-has-longer-memory-than-noise" class="md-nav__link">
    <span class="md-ellipsis">
      
        smooth has longer memory than noise
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Layers
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        layers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="layers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear" class="md-nav__link">
    <span class="md-ellipsis">
      
        FBMNoisyLinear
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FBMNoisyLinear">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear--replace-standard-linear-in-dqn-for-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Replace standard linear in DQN for exploration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.refresh_noise_stream" class="md-nav__link">
    <span class="md-ellipsis">
      
        refresh_noise_stream
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.reset_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FBMNoisyLinear.sample_noise" class="md-nav__link">
    <span class="md-ellipsis">
      
        sample_noise
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalKernel" class="md-nav__link">
    <span class="md-ellipsis">
      
        FractionalKernel
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FractionalKernel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalKernel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalPositionalEmbedding" class="md-nav__link">
    <span class="md-ellipsis">
      
        FractionalPositionalEmbedding
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FractionalPositionalEmbedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.FractionalPositionalEmbedding.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.layers.fractional_init_" class="md-nav__link">
    <span class="md-ellipsis">
      
        fractional_init_
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sde" class="md-nav__link">
    <span class="md-ellipsis">
      
        SDE
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.sde" class="md-nav__link">
    <span class="md-ellipsis">
      
        sde
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="sde">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE" class="md-nav__link">
    <span class="md-ellipsis">
      
        NeuralFSDE
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NeuralFSDE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE--define-drift-and-diffusion-networks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Define drift and diffusion networks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE--create-fsde-with-learnable-hurst-parameter" class="md-nav__link">
    <span class="md-ellipsis">
      
        Create fSDE with learnable Hurst parameter
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE--integrate-from-initial-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Integrate from initial conditions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE.H" class="md-nav__link">
    <span class="md-ellipsis">
      
        H
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.sde.NeuralFSDE.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Loss Functions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        loss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="loss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.HurstRegularizationLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        HurstRegularizationLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HurstRegularizationLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.HurstRegularizationLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.SpectralConsistencyLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        SpectralConsistencyLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SpectralConsistencyLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.loss.SpectralConsistencyLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#schedulers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Schedulers
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.schedulers" class="md-nav__link">
    <span class="md-ellipsis">
      
        schedulers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="schedulers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers--smooth-start-rough-end" class="md-nav__link">
    <span class="md-ellipsis">
      
        Smooth start, rough end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers.get_hurst_schedule" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_hurst_schedule
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="get_hurst_schedule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers.get_hurst_schedule--linear-schedule-from-rough-to-smooth" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear schedule from rough to smooth
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.schedulers.get_hurst_schedule--cosine-schedule-slower-at-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cosine schedule (slower at endpoints)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Augmentations
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      
        augmentations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="augmentations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        FractionalNoiseAugmentation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FractionalNoiseAugmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation--make-model-robust-to-trending-noise" class="md-nav__link">
    <span class="md-ellipsis">
      
        Make model robust to trending noise
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation--during-training-50-of-samples-get-fgn-added" class="md-nav__link">
    <span class="md-ellipsis">
      
        During training, 50% of samples get fGn added
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation--during-eval-no-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        During eval, no augmentation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.augmentations.FractionalNoiseAugmentation.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#online" class="md-nav__link">
    <span class="md-ellipsis">
      
        Online
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.online" class="md-nav__link">
    <span class="md-ellipsis">
      
        online
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="online">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.online.CachedFGNGenerator" class="md-nav__link">
    <span class="md-ellipsis">
      
        CachedFGNGenerator
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CachedFGNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.online.CachedFGNGenerator--generate-samples-one-at-a-time" class="md-nav__link">
    <span class="md-ellipsis">
      
        Generate samples one at a time
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.online.CachedFGNGenerator.step" class="md-nav__link">
    <span class="md-ellipsis">
      
        step
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reinforcement Learning
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.rl" class="md-nav__link">
    <span class="md-ellipsis">
      
        rl
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="rl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise" class="md-nav__link">
    <span class="md-ellipsis">
      
        FBMActionNoise
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FBMActionNoise">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise--for-stable-baselines3" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Stable Baselines3
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise--for-custom-pytorch-rl" class="md-nav__link">
    <span class="md-ellipsis">
      
        For custom PyTorch RL
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      
        __call__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.rl.FBMActionNoise.reset" class="md-nav__link">
    <span class="md-ellipsis">
      
        reset
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#utilities" class="md-nav__link">
    <span class="md-ellipsis">
      
        Utilities
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchfbm.utils" class="md-nav__link">
    <span class="md-ellipsis">
      
        utils
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchfbm.utils.get_cholesky_factor" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_cholesky_factor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.utils.get_fgn_autocovariance" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_fgn_autocovariance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfbm.utils.get_fgn_covariance_matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
        get_fgn_covariance_matrix
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="api-reference">API Reference</h1>
<p>This page documents the complete API of the <code>torchfbm</code> library.</p>
<h2 id="generators">Generators</h2>
<p>Core functions for generating fractional Brownian motion (fBm) and 
fractional Gaussian noise (fGn).</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.generators" class="doc doc-heading">
            <code>torchfbm.generators</code>


</h2>

    <div class="doc doc-contents first">

        <p>Fractional Brownian Motion and Fractional Gaussian Noise generators.</p>
<p>This module provides efficient algorithms for generating fBm paths and fGn samples,
including both exact (Cholesky) and approximate (Davies-Harte) methods.</p>
<p>The core mathematical foundation is based on Mandelbrot &amp; Van Ness (1968), with
generation algorithms from Davies &amp; Harte (1987) and Asmussen &amp; Glynn (2007).</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm import fbm, generate_davies_harte</p>
<h3 id="torchfbm.generators--generate-fbm-path-with-h07">Generate fBm path with H=0.7</h3>
<p>path = fbm(n=1000, H=0.7, size=(10,))</p>
<h3 id="torchfbm.generators--generate-fgn-increments">Generate fGn increments</h3>
<p>noise = generate_davies_harte(n=1000, H=0.7, size=(10,))</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.generators.fbm" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;davies_harte&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Generate Fractional Brownian Motion paths.</p>
<p>Based on Mandelbrot &amp; Van Ness (1968).</p>
<p>Fractional Brownian Motion <span class="arithmatex">\(B_H(t)\)</span> is a continuous-time Gaussian process with:</p>
<ul>
<li><span class="arithmatex">\(B_H(0) = 0\)</span></li>
<li><span class="arithmatex">\(\mathbb{E}[B_H(t)] = 0\)</span></li>
<li><span class="arithmatex">\(\text{Cov}(B_H(s), B_H(t)) = \frac{1}{2}(|s|^{2H} + |t|^{2H} - |t-s|^{2H})\)</span></li>
</ul>
<p>The Hurst exponent <span class="arithmatex">\(H \in (0, 1)\)</span> controls the path regularity:</p>
<ul>
<li><span class="arithmatex">\(H &lt; 0.5\)</span>: Rough paths, anti-persistent (mean-reverting)</li>
<li><span class="arithmatex">\(H = 0.5\)</span>: Standard Brownian motion</li>
<li><span class="arithmatex">\(H &gt; 0.5\)</span>: Smooth paths, persistent (trending)</li>
</ul>
<p>The fBm path is constructed by cumulative summation of fGn:</p>
<div class="arithmatex">\[B_H(t_k) = \sum_{i=1}^{k} X_i \quad \text{where } X \sim \text{fGn}(H)\]</div>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of increments. Output path has <span class="arithmatex">\(n+1\)</span> points (includes <span class="arithmatex">\(B_H(0)=0\)</span>).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst exponent in <span class="arithmatex">\((0, 1)\)</span>. Automatically clamped to <span class="arithmatex">\([0.01, 0.99]\)</span>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch dimensions. Output shape will be <code>(*size, n+1)</code>.</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method:
- 'davies_harte': Fast FFT-based, <span class="arithmatex">\(O(n \log n)\)</span> (default)
- 'cholesky': Exact but slow, <span class="arithmatex">\(O(n^3)\)</span></p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Torch device ('cpu' or 'cuda').</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type (torch.float32 or torch.float64).</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for reproducibility.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>fBm paths with shape <code>(*size, n+1)</code>. First element is always 0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>path = fbm(n=1000, H=0.7, size=(10,), seed=42)
assert path.shape == (10, 1001)
assert (path[:, 0] == 0).all()  # Starts at zero</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/generators.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="k">def</span><span class="w"> </span><span class="nf">fbm</span><span class="p">(</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate Fractional Brownian Motion paths.</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a><span class="sd">    Based on Mandelbrot &amp; Van Ness (1968).</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a><span class="sd">    Fractional Brownian Motion $B_H(t)$ is a continuous-time Gaussian process with:</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="sd">    - $B_H(0) = 0$</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="sd">    - $\\mathbb{E}[B_H(t)] = 0$</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="sd">    - $\\text{Cov}(B_H(s), B_H(t)) = \\frac{1}{2}(|s|^{2H} + |t|^{2H} - |t-s|^{2H})$</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="sd">    The Hurst exponent $H \\in (0, 1)$ controls the path regularity:</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">    - $H &lt; 0.5$: Rough paths, anti-persistent (mean-reverting)</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="sd">    - $H = 0.5$: Standard Brownian motion</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a><span class="sd">    - $H &gt; 0.5$: Smooth paths, persistent (trending)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a><span class="sd">    The fBm path is constructed by cumulative summation of fGn:</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="sd">    $$B_H(t_k) = \\sum_{i=1}^{k} X_i \\quad \\text{where } X \\sim \\text{fGn}(H)$$</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a><span class="sd">        n: Number of increments. Output path has $n+1$ points (includes $B_H(0)=0$).</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">        H: Hurst exponent in $(0, 1)$. Automatically clamped to $[0.01, 0.99]$.</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">        size: Batch dimensions. Output shape will be `(*size, n+1)`.</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a><span class="sd">        method: Generation method:</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">            - &#39;davies_harte&#39;: Fast FFT-based, $O(n \\log n)$ (default)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a><span class="sd">            - &#39;cholesky&#39;: Exact but slow, $O(n^3)$</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a><span class="sd">        device: Torch device (&#39;cpu&#39; or &#39;cuda&#39;).</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">        dtype: Data type (torch.float32 or torch.float64).</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">        seed: Random seed for reproducibility.</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">        return_numpy: If True, returns NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">        fBm paths with shape `(*size, n+1)`. First element is always 0.</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">        &gt;&gt;&gt; path = fbm(n=1000, H=0.7, size=(10,), seed=42)</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">        &gt;&gt;&gt; assert path.shape == (10, 1001)</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">        &gt;&gt;&gt; assert (path[:, 0] == 0).all()  # Starts at zero</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>    <span class="n">H</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">))</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;cholesky&quot;</span><span class="p">:</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>        <span class="n">func</span> <span class="o">=</span> <span class="n">generate_cholesky</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="n">func</span> <span class="o">=</span> <span class="n">generate_davies_harte</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>    <span class="n">fgn</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>    <span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">zeros</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">fgn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.generators.generate_cholesky" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate_cholesky</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Generate fractional Gaussian noise using Cholesky decomposition.</p>
<p>Exact method based on Asmussen &amp; Glynn (2007).</p>
<p>This method constructs the full covariance matrix <span class="arithmatex">\(\Sigma\)</span> and decomposes it as
<span class="arithmatex">\(\Sigma = LL^T\)</span> where <span class="arithmatex">\(L\)</span> is lower triangular. The fGn samples are then:</p>
<div class="arithmatex">\[X = L \cdot Z \quad \text{where } Z \sim \mathcal{N}(0, I)\]</div>


<details class="complexity" open>
  <summary>Complexity</summary>
  <ul>
<li>Time: <span class="arithmatex">\(O(n^3)\)</span> for Cholesky decomposition</li>
<li>Space: <span class="arithmatex">\(O(n^2)\)</span> for covariance matrix storage</li>
</ul>
</details>

<details class="note" open>
  <summary>Note</summary>
  <p>Exact but computationally expensive for large <span class="arithmatex">\(n\)</span>. Use Davies-Harte method
for <span class="arithmatex">\(n &gt; 1000\)</span>. May encounter numerical instability for <span class="arithmatex">\(H\)</span> close to 0 or 1
with large <span class="arithmatex">\(n\)</span>.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to generate (length of fGn sequence).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst exponent in <span class="arithmatex">\((0, 1)\)</span>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch dimensions. Output shape will be <code>(*size, n)</code>.</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Torch device ('cpu' or 'cuda').</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type (torch.float32 or torch.float64).</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for reproducibility.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fractional Gaussian noise samples with shape <code>(*size, n)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>fgn = generate_cholesky(n=100, H=0.7, size=(5,), seed=42)
assert fgn.shape == (5, 100)</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/generators.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="k">def</span><span class="w"> </span><span class="nf">generate_cholesky</span><span class="p">(</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate fractional Gaussian noise using Cholesky decomposition.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    Exact method based on Asmussen &amp; Glynn (2007).</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">    This method constructs the full covariance matrix $\\Sigma$ and decomposes it as</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    $\\Sigma = LL^T$ where $L$ is lower triangular. The fGn samples are then:</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">    $$X = L \\cdot Z \\quad \\text{where } Z \\sim \\mathcal{N}(0, I)$$</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    Complexity:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">        - Time: $O(n^3)$ for Cholesky decomposition</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        - Space: $O(n^2)$ for covariance matrix storage</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        Exact but computationally expensive for large $n$. Use Davies-Harte method</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        for $n &gt; 1000$. May encounter numerical instability for $H$ close to 0 or 1</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">        with large $n$.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        n: Number of samples to generate (length of fGn sequence).</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">        H: Hurst exponent in $(0, 1)$.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        size: Batch dimensions. Output shape will be `(*size, n)`.</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">        device: Torch device (&#39;cpu&#39; or &#39;cuda&#39;).</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">        dtype: Data type (torch.float32 or torch.float64).</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">        seed: Random seed for reproducibility.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">        return_numpy: If True, returns NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        Fractional Gaussian noise samples with shape `(*size, n)`.</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        &gt;&gt;&gt; fgn = generate_cholesky(n=100, H=0.7, size=(5,), seed=42)</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        &gt;&gt;&gt; assert fgn.shape == (5, 100)</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="n">generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="n">gamma</span> <span class="o">=</span> <span class="n">_autocovariance</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">lhs</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="n">rhs</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="n">distance_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">lhs</span> <span class="o">-</span> <span class="n">rhs</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">Sigma</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">[</span><span class="n">distance_matrix</span><span class="p">]</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">jitter</span> <span class="o">=</span> <span class="mf">1e-6</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">Sigma</span> <span class="o">+</span> <span class="n">jitter</span><span class="p">)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">Sigma</span> <span class="o">+</span> <span class="n">jitter</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">L</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.generators.generate_davies_harte" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate_davies_harte</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Generate fractional Gaussian noise using the Davies-Harte method.</p>
<p>Based on Davies &amp; Harte (1987).</p>
<p>This FFT-based method embeds the Toeplitz covariance matrix into a circulant
matrix, enabling efficient spectral factorization. The algorithm:</p>
<ol>
<li>Construct circulant embedding: <span class="arithmatex">\(c = [\gamma_0, ..., \gamma_{n-1}, \gamma_{n-2}, ..., \gamma_1]\)</span></li>
<li>Compute eigenvalues via FFT: <span class="arithmatex">\(\lambda = \text{FFT}(c)\)</span></li>
<li>Generate complex noise: <span class="arithmatex">\(W \sim \mathcal{CN}(0, I)\)</span></li>
<li>Apply spectral factorization: <span class="arithmatex">\(X = \text{IFFT}(\sqrt{\lambda} \cdot W)\)</span></li>
</ol>


<details class="complexity" open>
  <summary>Complexity</summary>
  <ul>
<li>Time: <span class="arithmatex">\(O(n \log n)\)</span> via FFT</li>
<li>Space: <span class="arithmatex">\(O(n)\)</span></li>
</ul>
</details>

<details class="warning" open>
  <summary>Warning</summary>
  <p>For some combinations of <span class="arithmatex">\(H\)</span> and <span class="arithmatex">\(n\)</span>, the circulant embedding may have
negative eigenvalues. These are clamped to zero with a warning. For exact
results in such cases, use the Cholesky method.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples to generate (length of fGn sequence).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst exponent in <span class="arithmatex">\((0, 1)\)</span>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch dimensions. Output shape will be <code>(*size, n)</code>.</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Torch device ('cpu' or 'cuda').</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type (torch.float32 or torch.float64).</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for reproducibility.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fractional Gaussian noise samples with shape <code>(*size, n)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>fgn = generate_davies_harte(n=10000, H=0.7, size=(100,), seed=42)
assert fgn.shape == (100, 10000)</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/generators.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="k">def</span><span class="w"> </span><span class="nf">generate_davies_harte</span><span class="p">(</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>    <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate fractional Gaussian noise using the Davies-Harte method.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">    Based on Davies &amp; Harte (1987).</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">    This FFT-based method embeds the Toeplitz covariance matrix into a circulant</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">    matrix, enabling efficient spectral factorization. The algorithm:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">    1. Construct circulant embedding: $c = [\\gamma_0, ..., \\gamma_{n-1}, \\gamma_{n-2}, ..., \\gamma_1]$</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">    2. Compute eigenvalues via FFT: $\\lambda = \\text{FFT}(c)$</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">    3. Generate complex noise: $W \\sim \\mathcal{CN}(0, I)$</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    4. Apply spectral factorization: $X = \\text{IFFT}(\\sqrt{\\lambda} \\cdot W)$</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">    Complexity:</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        - Time: $O(n \\log n)$ via FFT</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">        - Space: $O(n)$</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">    Warning:</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">        For some combinations of $H$ and $n$, the circulant embedding may have</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        negative eigenvalues. These are clamped to zero with a warning. For exact</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        results in such cases, use the Cholesky method.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        n: Number of samples to generate (length of fGn sequence).</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">        H: Hurst exponent in $(0, 1)$.</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">        size: Batch dimensions. Output shape will be `(*size, n)`.</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">        device: Torch device (&#39;cpu&#39; or &#39;cuda&#39;).</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">        dtype: Data type (torch.float32 or torch.float64).</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">        seed: Random seed for reproducibility.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">        return_numpy: If True, returns NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">        Fractional Gaussian noise samples with shape `(*size, n)`.</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">        &gt;&gt;&gt; fgn = generate_davies_harte(n=10000, H=0.7, size=(100,), seed=42)</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        &gt;&gt;&gt; assert fgn.shape == (100, 10000)</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>    <span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="n">generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="n">gamma</span> <span class="o">=</span> <span class="n">_autocovariance</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="c1"># Circulant embedding: [gamma_0, ..., gamma_{n-1}, gamma_{n-2}, ..., gamma_1]</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">gamma</span><span class="p">,</span> <span class="n">gamma</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="n">M</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="c1"># FFT (Real to Complex)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">.</span><span class="n">real</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>            <span class="s2">&quot;Negative eigenvalues encountered in Davies-Harte method, but zeroed out. &quot;</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="s2">&quot;Results may be inaccurate. Consider using &#39;cholesky&#39; method for exact results.&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>        <span class="n">lambdas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="c1"># Generate Complex White Noise with specific generator/dtype</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="n">rng_real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="n">rng_imag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="n">complex_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex</span><span class="p">(</span><span class="n">rng_real</span><span class="p">,</span> <span class="n">rng_imag</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">lambdas</span> <span class="o">/</span> <span class="n">M</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="n">fft_noise</span> <span class="o">=</span> <span class="n">complex_noise</span> <span class="o">*</span> <span class="n">scale</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="n">simulation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft</span><span class="p">(</span><span class="n">fft_noise</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">simulation</span><span class="o">.</span><span class="n">real</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">n</span><span class="p">]</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="estimators">Estimators</h2>
<p>Hurst parameter estimation using various statistical methods.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.estimators" class="doc doc-heading">
            <code>torchfbm.estimators</code>


</h2>

    <div class="doc doc-contents first">

        <p>Hurst exponent estimation methods.</p>
<p>This module provides differentiable estimators for the Hurst exponent,
enabling end-to-end training of models with fBm-related objectives.</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm import fbm, estimate_hurst
path = fbm(n=5000, H=0.7, size=(100,))
H_est = estimate_hurst(path)
print(f"Estimated H: {H_est.mean():.3f}")  # Should be ~0.7</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.estimators.estimate_hurst" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">estimate_hurst</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">min_lag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_lag</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">assume_path</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Estimate the Hurst exponent using the variogram method.</p>
<p>Based on Mandelbrot (1969) and the classical rescaled range analysis.</p>
<p>This method exploits the self-similarity property of fBm. For increments
at lag <span class="arithmatex">\(\tau\)</span>, the variance scales as:</p>
<div class="arithmatex">\[\text{Var}(B_H(t+\tau) - B_H(t)) \propto \tau^{2H}\]</div>
<p>Taking logarithms:</p>
<div class="arithmatex">\[\log(\text{Var}(\tau)) = 2H \cdot \log(\tau) + C\]</div>
<p>The Hurst exponent is estimated via linear regression in log-log space.</p>


<details class="note" open>
  <summary>Note</summary>
  <p>This estimator is differentiable and can be used in loss functions
for training neural networks with Hurst-regularized outputs.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input time series of shape <code>(batch, time)</code> or <code>(time,)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>min_lag</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum lag for variance estimation.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_lag</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum lag for variance estimation.</p>
              </div>
            </td>
            <td>
                  <code>20</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>assume_path</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, treats <code>x</code> as fBm path (default).
If False, treats <code>x</code> as fGn (increments) and integrates first.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimated Hurst exponent(s) clamped to <span class="arithmatex">\([0.01, 0.99]\)</span>.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape is <code>(batch,)</code> or scalar for 1D input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>path = fbm(n=5000, H=0.8, size=(50,), seed=42)
H_est = estimate_hurst(path, min_lag=2, max_lag=50)
assert abs(H_est.mean() - 0.8) &lt; 0.1  # Should be close to 0.8</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/estimators.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span>
<span class="normal"><a href="#__codelineno-0-86">86</a></span>
<span class="normal"><a href="#__codelineno-0-87">87</a></span>
<span class="normal"><a href="#__codelineno-0-88">88</a></span>
<span class="normal"><a href="#__codelineno-0-89">89</a></span>
<span class="normal"><a href="#__codelineno-0-90">90</a></span>
<span class="normal"><a href="#__codelineno-0-91">91</a></span>
<span class="normal"><a href="#__codelineno-0-92">92</a></span>
<span class="normal"><a href="#__codelineno-0-93">93</a></span>
<span class="normal"><a href="#__codelineno-0-94">94</a></span>
<span class="normal"><a href="#__codelineno-0-95">95</a></span>
<span class="normal"><a href="#__codelineno-0-96">96</a></span>
<span class="normal"><a href="#__codelineno-0-97">97</a></span>
<span class="normal"><a href="#__codelineno-0-98">98</a></span>
<span class="normal"><a href="#__codelineno-0-99">99</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="k">def</span><span class="w"> </span><span class="nf">estimate_hurst</span><span class="p">(</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="n">min_lag</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="n">max_lag</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">assume_path</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate the Hurst exponent using the variogram method.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    Based on Mandelbrot (1969) and the classical rescaled range analysis.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    This method exploits the self-similarity property of fBm. For increments</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    at lag $\\tau$, the variance scales as:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    $$\\text{Var}(B_H(t+\\tau) - B_H(t)) \\propto \\tau^{2H}$$</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    Taking logarithms:</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    $$\\log(\\text{Var}(\\tau)) = 2H \\cdot \\log(\\tau) + C$$</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    The Hurst exponent is estimated via linear regression in log-log space.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">        This estimator is differentiable and can be used in loss functions</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        for training neural networks with Hurst-regularized outputs.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        x: Input time series of shape `(batch, time)` or `(time,)`.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">        min_lag: Minimum lag for variance estimation.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        max_lag: Maximum lag for variance estimation.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        assume_path: If True, treats `x` as fBm path (default).</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">            If False, treats `x` as fGn (increments) and integrates first.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">        return_numpy: If True, returns NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        Estimated Hurst exponent(s) clamped to $[0.01, 0.99]$.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        Shape is `(batch,)` or scalar for 1D input.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        &gt;&gt;&gt; path = fbm(n=5000, H=0.8, size=(50,), seed=42)</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        &gt;&gt;&gt; H_est = estimate_hurst(path, min_lag=2, max_lag=50)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        &gt;&gt;&gt; assert abs(H_est.mean() - 0.8) &lt; 0.1  # Should be close to 0.8</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="c1"># Normalize to zero mean, unit variance for numerical stability</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="c1"># Integrate fGn to fBm path if needed</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">assume_path</span><span class="p">:</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="n">lags</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">min_lag</span><span class="p">,</span> <span class="n">max_lag</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="n">variances</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">lags</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="c1"># Compute increment variance at each scale</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">lag</span><span class="p">:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="k">break</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="n">increments</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">lag</span><span class="p">:]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="n">lag</span><span class="p">]</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="n">var</span> <span class="o">=</span> <span class="n">increments</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="n">variances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="c1"># Stack variances: Shape (Num_Lags, Batch)</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="n">variances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">variances</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="c1"># Log-log regression: log(Var) = 2H * log(lag) + C</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">variances</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="n">X</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lags</span><span class="p">[:</span> <span class="n">variances</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="p">)</span>  <span class="c1"># (Num_Lags, Batch)</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="c1"># Least squares slope estimation</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="n">X_mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="n">y_mean</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="n">numerator</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="n">denominator</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="n">slope</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="p">(</span><span class="n">denominator</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="c1"># Slope = 2H, so H = Slope / 2</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="n">H_est</span> <span class="o">=</span> <span class="n">slope</span> <span class="o">/</span> <span class="mf">2.0</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">H_est</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="dfa">DFA</h2>
<p>Detrended Fluctuation Analysis for detecting long-range correlations.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.dfa" class="doc doc-heading">
            <code>torchfbm.dfa</code>


</h2>

    <div class="doc doc-contents first">

        <p>Detrended Fluctuation Analysis (DFA) for scaling exponent estimation.</p>
<p>This module provides GPU-accelerated DFA for measuring long-range correlations
in time series. DFA is particularly useful for non-stationary signals.</p>
<p>Based on Peng et al. (1994).</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm import fbm
from torchfbm.dfa import dfa
path = fbm(n=10000, H=0.7, size=(10,))
alpha = dfa(path)
print(f"DFA exponent: {alpha.mean():.3f}")  # Should be ~0.7</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.dfa.dfa" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">dfa</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_alpha</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute Detrended Fluctuation Analysis scaling exponent.</p>
<p>Based on Peng et al. (1994).</p>
<p>DFA measures the scaling behavior of the fluctuation function <span class="arithmatex">\(F(s)\)</span>:</p>
<div class="arithmatex">\[F(s) \sim s^{\alpha}\]</div>
<p>where <span class="arithmatex">\(s\)</span> is the scale (window size) and <span class="arithmatex">\(\alpha\)</span> is the scaling exponent.</p>
<p>For fBm, <span class="arithmatex">\(\alpha = H\)</span> (the Hurst exponent). The relationship between DFA
exponent and correlation structure:</p>
<ul>
<li><span class="arithmatex">\(\alpha &lt; 0.5\)</span>: Anti-correlated (mean-reverting)</li>
<li><span class="arithmatex">\(\alpha = 0.5\)</span>: Uncorrelated (white noise)</li>
<li><span class="arithmatex">\(0.5 &lt; \alpha &lt; 1\)</span>: Long-range correlated</li>
<li><span class="arithmatex">\(\alpha = 1\)</span>: <span class="arithmatex">\(1/f\)</span> noise (pink noise)</li>
<li><span class="arithmatex">\(\alpha &gt; 1\)</span>: Non-stationary, unbounded</li>
</ul>


<details class="algorithm" open>
  <summary>Algorithm</summary>
  <ol>
<li>Compute profile: <span class="arithmatex">\(y(k) = \sum_{i=1}^{k}(x_i - \bar{x})\)</span></li>
<li>Divide into segments of size <span class="arithmatex">\(s\)</span></li>
<li>Fit polynomial trend in each segment</li>
<li>Compute RMS of detrended fluctuations: <span class="arithmatex">\(F(s)\)</span></li>
<li>Regress <span class="arithmatex">\(\log F(s)\)</span> vs <span class="arithmatex">\(\log s\)</span> to get <span class="arithmatex">\(\alpha\)</span></li>
</ol>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Time series tensor of shape <code>(batch, time)</code> or <code>(time,)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>scales</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of window sizes. If None, uses 20 log-spaced scales.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Polynomial order for detrending:
- 1: Linear (DFA1, removes linear trends)
- 2: Quadratic (DFA2, removes parabolic trends)
- 3: Cubic (DFA3)</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_alpha</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns scaling exponent <span class="arithmatex">\(\alpha\)</span>.
If False, returns tuple <code>(F, scales)</code> with raw fluctuation function.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>return_alpha=True</code>: Scaling exponent(s) of shape <code>(batch,)</code>.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>return_alpha=False</code>: Tuple of (fluctuation tensor, scales array).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>path = fbm(n=10000, H=0.8, size=(20,), seed=42)
alpha = dfa(path, order=2)
assert abs(alpha.mean() - 0.8) &lt; 0.1</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/dfa.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="k">def</span><span class="w"> </span><span class="nf">dfa</span><span class="p">(</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="n">scales</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>    <span class="n">return_alpha</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Detrended Fluctuation Analysis scaling exponent.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    Based on Peng et al. (1994).</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    DFA measures the scaling behavior of the fluctuation function $F(s)$:</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    $$F(s) \\sim s^{\\alpha}$$</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    where $s$ is the scale (window size) and $\\alpha$ is the scaling exponent.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    For fBm, $\\alpha = H$ (the Hurst exponent). The relationship between DFA</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    exponent and correlation structure:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">    - $\\alpha &lt; 0.5$: Anti-correlated (mean-reverting)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    - $\\alpha = 0.5$: Uncorrelated (white noise)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">    - $0.5 &lt; \\alpha &lt; 1$: Long-range correlated</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    - $\\alpha = 1$: $1/f$ noise (pink noise)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    - $\\alpha &gt; 1$: Non-stationary, unbounded</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Algorithm:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        1. Compute profile: $y(k) = \\sum_{i=1}^{k}(x_i - \\bar{x})$</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        2. Divide into segments of size $s$</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">        3. Fit polynomial trend in each segment</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        4. Compute RMS of detrended fluctuations: $F(s)$</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        5. Regress $\\log F(s)$ vs $\\log s$ to get $\\alpha$</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        x: Time series tensor of shape `(batch, time)` or `(time,)`.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        scales: List of window sizes. If None, uses 20 log-spaced scales.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        order: Polynomial order for detrending:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">            - 1: Linear (DFA1, removes linear trends)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">            - 2: Quadratic (DFA2, removes parabolic trends)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">            - 3: Cubic (DFA3)</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        return_alpha: If True, returns scaling exponent $\\alpha$.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">            If False, returns tuple `(F, scales)` with raw fluctuation function.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        If `return_alpha=True`: Scaling exponent(s) of shape `(batch,)`.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        If `return_alpha=False`: Tuple of (fluctuation tensor, scales array).</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        &gt;&gt;&gt; path = fbm(n=10000, H=0.8, size=(20,), seed=42)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        &gt;&gt;&gt; alpha = dfa(path, order=2)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        &gt;&gt;&gt; assert abs(alpha.mean() - 0.8) &lt; 0.1</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="c1"># Handle 1D input</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="c1"># Compute profile: y(k) = cumsum(x - mean)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="c1"># Default: 20 logarithmically-spaced scales</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="k">if</span> <span class="n">scales</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">min_scale</span> <span class="o">=</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">2</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="n">max_scale</span> <span class="o">=</span> <span class="n">N</span> <span class="o">//</span> <span class="mi">4</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="n">scales</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>            <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">min_scale</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">max_scale</span><span class="p">),</span> <span class="n">num</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="n">fluctuations</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">scales</span><span class="p">:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="c1"># Segment profile into non-overlapping windows</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="n">n_segments</span> <span class="o">=</span> <span class="n">N</span> <span class="o">//</span> <span class="n">s</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="n">limit</span> <span class="o">=</span> <span class="n">n_segments</span> <span class="o">*</span> <span class="n">s</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="n">y_truncated</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="p">:</span><span class="n">limit</span><span class="p">]</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="n">y_segmented</span> <span class="o">=</span> <span class="n">y_truncated</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_segments</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="c1"># Batched polynomial detrending via pseudo-inverse</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">t</span><span class="o">**</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>            <span class="n">coeffs_op</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="k">except</span><span class="p">:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>            <span class="n">coeffs_op</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">y_segmented</span><span class="p">,</span> <span class="n">coeffs_op</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="n">trend</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="c1"># RMS of detrended fluctuations</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="n">rms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_segmented</span> <span class="o">-</span> <span class="n">trend</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="n">F_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rms</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="n">fluctuations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F_s</span><span class="p">)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="c1"># Stack fluctuations: (Batch, Num_Scales)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">F</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">fluctuations</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_alpha</span><span class="p">:</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">return</span> <span class="n">F</span><span class="p">,</span> <span class="n">scales</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="c1"># Log-log regression: log(F) = alpha * log(s) + C</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="n">log_F</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">F</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="n">log_scales</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>    <span class="n">S_xx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">log_scales</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>    <span class="n">mean_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_scales</span><span class="p">)</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="n">mean_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">log_F</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>    <span class="c1"># Broadcast subtraction</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="n">S_xy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">log_scales</span> <span class="o">-</span> <span class="n">mean_x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">log_F</span> <span class="o">-</span> <span class="n">mean_y</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>    <span class="n">alpha</span> <span class="o">=</span> <span class="n">S_xy</span> <span class="o">/</span> <span class="n">S_xx</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>    <span class="k">return</span> <span class="n">alpha</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="analysis">Analysis</h2>
<p>Statistical analysis utilities for fBm/fGn data.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.analysis" class="doc doc-heading">
            <code>torchfbm.analysis</code>


</h2>

    <div class="doc doc-contents first">

        <p>Analysis utilities for Fractional Brownian Motion.</p>
<p>This module provides tools for analyzing and visualizing fBm/fGn processes,
including covariance matrix construction, autocorrelation plotting, and
spectral analysis.</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.analysis import covariance_matrix, spectral_scaling_factor
cov = covariance_matrix(n=100, H=0.7)
freqs = torch.linspace(0.01, 0.5, 50)
scaling = spectral_scaling_factor(freqs, H=0.7)</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.analysis.covariance_matrix" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">covariance_matrix</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Construct the exact autocovariance matrix for fractional Gaussian noise.</p>
<p>Builds the symmetric Toeplitz covariance matrix <span class="arithmatex">\(\Sigma\)</span> for fGn, where each
entry <span class="arithmatex">\(\Sigma_{ij} = \gamma(|i-j|)\)</span> is determined by the autocovariance function.</p>
<p>Based on Mandelbrot &amp; Van Ness (1968).</p>
<p>The autocovariance function for fGn is:</p>
<div class="arithmatex">\[\gamma(k) = \frac{1}{2}\left(|k+1|^{2H} - 2|k|^{2H} + |k-1|^{2H}\right)\]</div>
<p>This matrix is positive semi-definite and can be Cholesky decomposed for
exact fGn generation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Size of the covariance matrix (n  n).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst exponent in <span class="arithmatex">\((0, 1)\)</span>. Controls the correlation structure:
- <span class="arithmatex">\(H &lt; 0.5\)</span>: Anti-persistent (negative correlations)
- <span class="arithmatex">\(H = 0.5\)</span>: Standard Brownian motion (independent increments)
- <span class="arithmatex">\(H &gt; 0.5\)</span>: Persistent (positive correlations)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Torch device for computation ('cpu' or 'cuda').</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns a NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Symmetric positive semi-definite Toeplitz matrix of shape <span class="arithmatex">\((n, n)\)</span>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>cov = covariance_matrix(n=50, H=0.8)
assert cov.shape == (50, 50)
assert torch.allclose(cov, cov.T)  # Symmetric</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/analysis.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="k">def</span><span class="w"> </span><span class="nf">covariance_matrix</span><span class="p">(</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Construct the exact autocovariance matrix for fractional Gaussian noise.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    Builds the symmetric Toeplitz covariance matrix $\\Sigma$ for fGn, where each</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    entry $\\Sigma_{ij} = \\gamma(|i-j|)$ is determined by the autocovariance function.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    Based on Mandelbrot &amp; Van Ness (1968).</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    The autocovariance function for fGn is:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    $$\\gamma(k) = \\frac{1}{2}\\left(|k+1|^{2H} - 2|k|^{2H} + |k-1|^{2H}\\right)$$</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    This matrix is positive semi-definite and can be Cholesky decomposed for</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    exact fGn generation.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">        n: Size of the covariance matrix (n  n).</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        H: Hurst exponent in $(0, 1)$. Controls the correlation structure:</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">            - $H &lt; 0.5$: Anti-persistent (negative correlations)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">            - $H = 0.5$: Standard Brownian motion (independent increments)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">            - $H &gt; 0.5$: Persistent (positive correlations)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">        device: Torch device for computation (&#39;cpu&#39; or &#39;cuda&#39;).</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        return_numpy: If True, returns a NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        Symmetric positive semi-definite Toeplitz matrix of shape $(n, n)$.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        &gt;&gt;&gt; cov = covariance_matrix(n=50, H=0.8)</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        &gt;&gt;&gt; assert cov.shape == (50, 50)</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        &gt;&gt;&gt; assert torch.allclose(cov, cov.T)  # Symmetric</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">.generators</span><span class="w"> </span><span class="kn">import</span> <span class="n">_autocovariance</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>    <span class="n">gamma</span> <span class="o">=</span> <span class="n">_autocovariance</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>    <span class="c1"># Construct Toeplitz matrix from autocovariance</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="n">distance_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">idx</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">[</span><span class="n">distance_matrix</span><span class="p">]</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.analysis.plot_acf" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_acf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">max_lag</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Autocorrelation&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Plot the autocorrelation function of a time series.</p>
<p>Computes and visualizes the ACF using FFT-based circular convolution for
efficient <span class="arithmatex">\(O(N \log N)\)</span> computation.</p>
<p>The autocorrelation at lag <span class="arithmatex">\(k\)</span> is defined as:</p>
<div class="arithmatex">\[\rho(k) = \frac{\text{Cov}(X_t, X_{t+k})}{\text{Var}(X_t)}\]</div>
<p>For fGn with Hurst exponent <span class="arithmatex">\(H\)</span>, the theoretical ACF decays as:</p>
<div class="arithmatex">\[\rho(k) \sim H(2H-1)|k|^{2H-2} \quad \text{as } k \to \infty\]</div>


<details class="note" open>
  <summary>Note</summary>
  <p>Requires matplotlib to be installed separately.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input time series tensor. Last dimension is treated as time axis.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_lag</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum lag to display in the plot.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>title</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Title for the plot.</p>
              </div>
            </td>
            <td>
                  <code>&#39;Autocorrelation&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None. Displays the plot using matplotlib.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm import fbm
path = fbm(n=1000, H=0.7, size=(1,))
plot_acf(path.squeeze(), max_lag=50, title="fBm ACF (H=0.7)")</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/analysis.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="k">def</span><span class="w"> </span><span class="nf">plot_acf</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">max_lag</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Autocorrelation&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot the autocorrelation function of a time series.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    Computes and visualizes the ACF using FFT-based circular convolution for</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">    efficient $O(N \\log N)$ computation.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    The autocorrelation at lag $k$ is defined as:</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">    $$\\rho(k) = \\frac{\\text{Cov}(X_t, X_{t+k})}{\\text{Var}(X_t)}$$</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    For fGn with Hurst exponent $H$, the theoretical ACF decays as:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">    $$\\rho(k) \\sim H(2H-1)|k|^{2H-2} \\quad \\text{as } k \\to \\infty$$</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        Requires matplotlib to be installed separately.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">        x: Input time series tensor. Last dimension is treated as time axis.</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">        max_lag: Maximum lag to display in the plot.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        title: Title for the plot.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">        None. Displays the plot using matplotlib.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">        &gt;&gt;&gt; from torchfbm import fbm</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">        &gt;&gt;&gt; path = fbm(n=1000, H=0.7, size=(1,))</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        &gt;&gt;&gt; plot_acf(path.squeeze(), max_lag=50, title=&quot;fBm ACF (H=0.7)&quot;)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matplotlib not installed.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="k">return</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="c1"># FFT-based ACF computation</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="n">x_centered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="n">next_pow2</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bit_length</span><span class="p">()</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="c1"># Zero-pad to next power of 2 for efficiency and avoid circular correlation</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="n">x_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x_centered</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">next_pow2</span> <span class="o">-</span> <span class="n">n</span><span class="p">))</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">fft</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">x_padded</span><span class="p">)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="n">power</span> <span class="o">=</span> <span class="n">fft</span> <span class="o">*</span> <span class="n">fft</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">acf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft</span><span class="p">(</span><span class="n">power</span><span class="p">)</span><span class="o">.</span><span class="n">real</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">acf</span> <span class="o">=</span> <span class="n">acf</span><span class="p">[:</span><span class="n">max_lag</span><span class="p">]</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">acf</span> <span class="o">=</span> <span class="n">acf</span> <span class="o">/</span> <span class="n">acf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="n">acf_np</span> <span class="o">=</span> <span class="n">acf</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">acf_np</span><span class="p">)),</span> <span class="n">acf_np</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Lag&quot;</span><span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Correlation&quot;</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.analysis.spectral_scaling_factor" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">spectral_scaling_factor</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute the spectral scaling factor for fBm spectral synthesis.</p>
<p>Returns the amplitude scaling <span class="arithmatex">\(A(f)\)</span> needed to synthesize fBm via spectral
methods. Based on the <span class="arithmatex">\(1/f^\beta\)</span> power spectral density law.</p>
<p>Based on Flandrin (1989) and Mandelbrot &amp; Van Ness (1968).</p>
<p>The power spectral density of fBm scales as:</p>
<div class="arithmatex">\[S(f) \propto \frac{1}{|f|^\beta} \quad \text{where } \beta = 2H + 1\]</div>
<p>The amplitude scaling is therefore:</p>
<div class="arithmatex">\[A(f) = \frac{1}{|f|^{(H + 0.5)}}\]</div>
<p>This is used in the spectral synthesis method where fBm is generated by
filtering white noise with this frequency-dependent amplitude.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>f</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Frequency tensor. Can be any shape; scaling is applied element-wise.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst exponent in <span class="arithmatex">\((0, 1)\)</span>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns a NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Spectral scaling factors with same shape as input <code>f</code>.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>DC component (<span class="arithmatex">\(f=0\)</span>) is set to zero.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>freqs = torch.linspace(0.01, 0.5, 100)
scaling = spectral_scaling_factor(freqs, H=0.7)</p>
<h4 id="torchfbm.analysis.spectral_scaling_factor--use-for-spectral-synthesis-fft_coeffs-white_noise-scaling">Use for spectral synthesis: fft_coeffs = white_noise * scaling</h4>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/analysis.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="k">def</span><span class="w"> </span><span class="nf">spectral_scaling_factor</span><span class="p">(</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="n">f</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the spectral scaling factor for fBm spectral synthesis.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">    Returns the amplitude scaling $A(f)$ needed to synthesize fBm via spectral</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">    methods. Based on the $1/f^\\beta$ power spectral density law.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    Based on Flandrin (1989) and Mandelbrot &amp; Van Ness (1968).</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">    The power spectral density of fBm scales as:</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">    $$S(f) \\propto \\frac{1}{|f|^\\beta} \\quad \\text{where } \\beta = 2H + 1$$</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">    The amplitude scaling is therefore:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">    $$A(f) = \\frac{1}{|f|^{(H + 0.5)}}$$</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">    This is used in the spectral synthesis method where fBm is generated by</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    filtering white noise with this frequency-dependent amplitude.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        f: Frequency tensor. Can be any shape; scaling is applied element-wise.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">        H: Hurst exponent in $(0, 1)$.</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">        return_numpy: If True, returns a NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        Spectral scaling factors with same shape as input `f`.</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        DC component ($f=0$) is set to zero.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        &gt;&gt;&gt; freqs = torch.linspace(0.01, 0.5, 100)</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">        &gt;&gt;&gt; scaling = spectral_scaling_factor(freqs, H=0.7)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">        &gt;&gt;&gt; # Use for spectral synthesis: fft_coeffs = white_noise * scaling</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="n">beta</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">H</span> <span class="o">+</span> <span class="mi">1</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="n">safe_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">f</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">f</span><span class="p">)</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="n">scaling</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">safe_f</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">beta</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">))</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="n">scaling</span><span class="p">[</span><span class="n">f</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Zero DC component</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="k">return</span> <span class="n">scaling</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">scaling</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="processes">Processes</h2>
<p>Stochastic processes driven by fractional Brownian motion.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.processes" class="doc doc-heading">
            <code>torchfbm.processes</code>


</h2>

    <div class="doc doc-contents first">

        <p>Stochastic processes driven by fractional Brownian motion.</p>
<p>This module provides implementations of various stochastic processes that
incorporate fractional Brownian motion as the driving noise, enabling
simulation of systems with long-range dependence and anomalous diffusion.</p>


<details class="processes-included" open>
  <summary>Processes Included</summary>
  <ul>
<li><strong>Fractional Ornstein-Uhlenbeck</strong>: Mean-reverting process with memory</li>
<li><strong>Geometric fBm</strong>: Asset price model with long-range dependence</li>
<li><strong>Reflected fBm</strong>: Bounded fBm with reflection barriers</li>
<li><strong>Fractional Brownian Bridge</strong>: fBm conditioned on endpoint</li>
<li><strong>Multifractal Random Walk</strong>: Volatility clustering model</li>
</ul>
</details>

<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.processes import fractional_ou_process, geometric_fbm</p>
<h3 id="torchfbm.processes--mean-reverting-process-with-memory">Mean-reverting process with memory</h3>
<p>ou = fractional_ou_process(1000, H=0.7, theta=0.5, mu=0.0)</p>
<h3 id="torchfbm.processes--asset-prices-with-long-range-dependence">Asset prices with long-range dependence</h3>
<p>prices = geometric_fbm(252, H=0.6, mu=0.05, sigma=0.2, s0=100)</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.processes.fractional_brownian_bridge" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fractional_brownian_bridge</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">start_val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">end_val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">t_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;davies_harte&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Simulate a Fractional Brownian Bridge.</p>
<p>Generates fBm conditioned on fixed start and end values.
Based on the pinning method described in Norros, Valkeila &amp; Virtamo (1999).</p>
<p>The bridge is constructed using linear correction of a free fBm path:</p>
<div class="arithmatex">\[B^{H,bridge}_t = B^H_t - \frac{t}{T}(B^H_T - (end - start)) + start\]</div>
<p>This produces a "rough" path (for <span class="arithmatex">\(H &lt; 0.5\)</span>) or "smooth" path (for <span class="arithmatex">\(H &gt; 0.5\)</span>)
that is pinned to specific boundary values.</p>


<details class="applications" open>
  <summary>Applications</summary>
  <ul>
<li><strong>Finance</strong>: Modeling prices with known future values (options at expiry)</li>
<li><strong>Simulation</strong>: Conditioning on observed endpoints</li>
<li><strong>Interpolation</strong>: Rough path interpolation between data points</li>
<li><strong>Testing</strong>: Generating paths with known boundary conditions</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of time steps.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter in (0, 1).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>start_val</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Starting value <span class="arithmatex">\(B^{H,bridge}_0\)</span>.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>end_val</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Ending value <span class="arithmatex">\(B^{H,bridge}_T\)</span>.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>t_max</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total time horizon <span class="arithmatex">\(T\)</span>.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Volatility scaling.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch dimensions.</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method ('davies_harte' or 'cholesky').</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computation device.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor of shape <code>(*size, n+1)</code> with bridge paths.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.processes.fractional_brownian_bridge--bridge-from-0-to-1-with-rough-texture">Bridge from 0 to 1 with rough texture</h4>
<p>bridge = fractional_brownian_bridge(
...     n=1000, H=0.3, start_val=0.0, end_val=1.0
... )
print(bridge[0, 0], bridge[0, -1])  # ~0.0, ~1.0</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/processes.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="k">def</span><span class="w"> </span><span class="nf">fractional_brownian_bridge</span><span class="p">(</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>    <span class="n">start_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>    <span class="n">end_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>    <span class="n">t_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>    <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>    <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="p">):</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulate a Fractional Brownian Bridge.</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">    Generates fBm conditioned on fixed start and end values.</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a><span class="sd">    Based on the pinning method described in Norros, Valkeila &amp; Virtamo (1999).</span>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a><span class="sd">    The bridge is constructed using linear correction of a free fBm path:</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a><span class="sd">    $$B^{H,bridge}_t = B^H_t - \\frac{t}{T}(B^H_T - (end - start)) + start$$</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="sd">    This produces a &quot;rough&quot; path (for $H &lt; 0.5$) or &quot;smooth&quot; path (for $H &gt; 0.5$)</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">    that is pinned to specific boundary values.</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">    Applications:</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">        - **Finance**: Modeling prices with known future values (options at expiry)</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a><span class="sd">        - **Simulation**: Conditioning on observed endpoints</span>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a><span class="sd">        - **Interpolation**: Rough path interpolation between data points</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a><span class="sd">        - **Testing**: Generating paths with known boundary conditions</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a><span class="sd">        n: Number of time steps.</span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a><span class="sd">        H: Hurst parameter in (0, 1).</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a><span class="sd">        start_val: Starting value $B^{H,bridge}_0$.</span>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a><span class="sd">        end_val: Ending value $B^{H,bridge}_T$.</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a><span class="sd">        t_max: Total time horizon $T$.</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a><span class="sd">        sigma: Volatility scaling.</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a><span class="sd">        size: Batch dimensions.</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a><span class="sd">        method: Generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a><span class="sd">        device: Computation device.</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a><span class="sd">        return_numpy: If True, returns NumPy array.</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="sd">        Tensor of shape ``(*size, n+1)`` with bridge paths.</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a><span class="sd">        &gt;&gt;&gt; # Bridge from 0 to 1 with rough texture</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a><span class="sd">        &gt;&gt;&gt; bridge = fractional_brownian_bridge(</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a><span class="sd">        ...     n=1000, H=0.3, start_val=0.0, end_val=1.0</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a><span class="sd">        &gt;&gt;&gt; print(bridge[0, 0], bridge[0, -1])  # ~0.0, ~1.0</span>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a>    <span class="c1"># 1. Generate a FREE unconditioned path starting at 0</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a>    <span class="c1"># We use fbm() to handle H-clamping and method selection</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a>    <span class="c1"># shape: (..., n+1)</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a>    <span class="n">free_path</span> <span class="o">=</span> <span class="n">fbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>    <span class="c1"># 2. Scale the free path to physical time/sigma</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>    <span class="c1"># Scale factor for variance over time T is T^(2H)</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>    <span class="c1"># The generator gives us unit step variance.</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>    <span class="n">scale_factor</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="p">(</span><span class="n">t_max</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">**</span> <span class="n">H</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>    <span class="n">free_path</span> <span class="o">=</span> <span class="n">free_path</span> <span class="o">*</span> <span class="n">scale_factor</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>    <span class="c1"># 3. Create the Time Grid</span>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>    <span class="c1"># Shape: (1, ..., n+1) to broadcast correctly</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">t_max</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>    <span class="c1"># Reshape for broadcasting against &#39;size&#39;</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>    <span class="c1"># If size=(Batch, ), free_path is (Batch, n+1).</span>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>    <span class="c1"># We need t_grid to be (1, n+1) compatible.</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">size</span><span class="p">)):</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>        <span class="n">t_grid</span> <span class="o">=</span> <span class="n">t_grid</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>    <span class="c1"># 4. Calculate the Bridge &quot;Drift&quot;</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>    <span class="c1"># We need to subtract the error at the end.</span>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>    <span class="c1"># The free path ends at X_T. We want it to end at (end_val - start_val).</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>    <span class="c1"># Current endpoint error = free_path[..., -1]</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a>    <span class="n">current_end</span> <span class="o">=</span> <span class="n">free_path</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># Keep dims for broadcast</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a>    <span class="n">target_displacement</span> <span class="o">=</span> <span class="n">end_val</span> <span class="o">-</span> <span class="n">start_val</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>    <span class="c1"># The correction term is linear interpolation of the error</span>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>    <span class="c1"># Correction(t) = (t / T) * (current_end - target_displacement)</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>    <span class="n">correction</span> <span class="o">=</span> <span class="p">(</span><span class="n">t_grid</span> <span class="o">/</span> <span class="n">t_max</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">current_end</span> <span class="o">-</span> <span class="n">target_displacement</span><span class="p">)</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a>    <span class="c1"># 5. Apply correction and shift start</span>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a>    <span class="n">bridge</span> <span class="o">=</span> <span class="n">free_path</span> <span class="o">-</span> <span class="n">correction</span> <span class="o">+</span> <span class="n">start_val</span>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>    <span class="k">return</span> <span class="n">bridge</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">bridge</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.processes.fractional_ou_process" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fractional_ou_process</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;davies_harte&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Simulate a Fractional Ornstein-Uhlenbeck (fOU) process.</p>
<p>Based on Cheridito, Kawaguchi &amp; Maejima (2003).</p>
<p>The fOU process is defined by the stochastic differential equation:</p>
<div class="arithmatex">\[dX_t = \theta(\mu - X_t)dt + \sigma dB^H_t\]</div>
<p>where:
- <span class="arithmatex">\(\theta\)</span> is the mean-reversion speed
- <span class="arithmatex">\(\mu\)</span> is the long-term mean
- <span class="arithmatex">\(\sigma\)</span> is the volatility
- <span class="arithmatex">\(B^H_t\)</span> is fractional Brownian motion with Hurst parameter <span class="arithmatex">\(H\)</span></p>


<details class="properties" open>
  <summary>Properties</summary>
  <ul>
<li><strong>H &gt; 0.5</strong>: Persistent memory, slower mean-reversion than standard OU</li>
<li><strong>H = 0.5</strong>: Reduces to standard OU process</li>
<li><strong>H &lt; 0.5</strong>: Anti-persistent, faster mean-reversion</li>
</ul>
</details>        <p>The process is stationary and mean-reverting, but unlike standard OU,
it exhibits long-range dependence when <span class="arithmatex">\(H \neq 0.5\)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of time steps.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter in (0, 1). Controls memory persistence.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>theta</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mean-reversion speed. Higher values = faster reversion.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mu</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Long-term mean level.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Volatility coefficient.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dt</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Time step size.</p>
              </div>
            </td>
            <td>
                  <code>0.01</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch dimensions for multiple sample paths.</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method, either 'davies_harte' (fast) or 'cholesky' (exact).</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computation device ('cpu' or 'cuda').</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for tensors.</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor of shape <code>(*size, n+1)</code> containing the simulated paths.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.processes.fractional_ou_process--simulate-interest-rate-with-memory">Simulate interest rate with memory</h4>
<p>rates = fractional_ou_process(
...     n=1000, H=0.7, theta=0.1, mu=0.05, sigma=0.01
... )</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/processes.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="k">def</span><span class="w"> </span><span class="nf">fractional_ou_process</span><span class="p">(</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>    <span class="n">mu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="n">dt</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="p">):</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulate a Fractional Ornstein-Uhlenbeck (fOU) process.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">    Based on Cheridito, Kawaguchi &amp; Maejima (2003).</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    The fOU process is defined by the stochastic differential equation:</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    $$dX_t = \\theta(\\mu - X_t)dt + \\sigma dB^H_t$$</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">    where:</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    - $\\theta$ is the mean-reversion speed</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    - $\\mu$ is the long-term mean</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    - $\\sigma$ is the volatility</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    - $B^H_t$ is fractional Brownian motion with Hurst parameter $H$</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">    Properties:</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        - **H &gt; 0.5**: Persistent memory, slower mean-reversion than standard OU</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        - **H = 0.5**: Reduces to standard OU process</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        - **H &lt; 0.5**: Anti-persistent, faster mean-reversion</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    The process is stationary and mean-reverting, but unlike standard OU,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">    it exhibits long-range dependence when $H \\neq 0.5$.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        n: Number of time steps.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        H: Hurst parameter in (0, 1). Controls memory persistence.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        theta: Mean-reversion speed. Higher values = faster reversion.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        mu: Long-term mean level.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        sigma: Volatility coefficient.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        dt: Time step size.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        size: Batch dimensions for multiple sample paths.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        method: Generation method, either &#39;davies_harte&#39; (fast) or &#39;cholesky&#39; (exact).</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        device: Computation device (&#39;cpu&#39; or &#39;cuda&#39;).</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        dtype: Data type for tensors.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        return_numpy: If True, returns NumPy array.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">        Tensor of shape ``(*size, n+1)`` containing the simulated paths.</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">        &gt;&gt;&gt; # Simulate interest rate with memory</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        &gt;&gt;&gt; rates = fractional_ou_process(</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        ...     n=1000, H=0.7, theta=0.1, mu=0.05, sigma=0.01</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="c1"># Clamp H to valid range (0, 1)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="n">H</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">))</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;cholesky&quot;</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_cholesky</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_davies_harte</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="c1"># Generate fGn and scale by dt^H</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="n">fgn</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="n">noise_term</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">fgn</span> <span class="o">*</span> <span class="p">(</span><span class="n">dt</span><span class="o">**</span><span class="n">H</span><span class="p">)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="c1"># Euler-Maruyama integration</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span>  <span class="c1"># Start at mean</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="n">drift_factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">dt</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="n">drift_constant</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">dt</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">*</span> <span class="n">drift_factor</span> <span class="o">+</span> <span class="n">drift_constant</span> <span class="o">+</span> <span class="n">noise_term</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.processes.geometric_fbm" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">geometric_fbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">t_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">s0</span><span class="o">=</span><span class="mf">100.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;davies_harte&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Simulate Geometric Fractional Brownian Motion (GFBm).</p>
<p>Generalization of Geometric Brownian Motion with long-range dependence.
Based on the framework described in Rogers (1997).</p>
<p>The price follows:</p>
<div class="arithmatex">\[S_t = S_0 \exp\left((\mu - \frac{1}{2}\sigma^2)t + \sigma B^H_t\right)\]</div>
<p>where:
- <span class="arithmatex">\(S_0\)</span> is the initial price
- <span class="arithmatex">\(\mu\)</span> is the drift (expected return)
- <span class="arithmatex">\(\sigma\)</span> is the volatility
- <span class="arithmatex">\(B^H_t\)</span> is fractional Brownian motion</p>


<details class="note" open>
  <summary>Note</summary>
  <p>Unlike standard GBM, GFBm with <span class="arithmatex">\(H \neq 0.5\)</span> admits arbitrage in
continuous time. However, it remains useful for modeling observed
market properties like volatility clustering and trend persistence.</p>
</details>

<details class="applications" open>
  <summary>Applications</summary>
  <ul>
<li><strong>Finance</strong>: Modeling assets with trending behavior (<span class="arithmatex">\(H &gt; 0.5\)</span>)</li>
<li><strong>Volatility modeling</strong>: Capturing long-memory in volatility</li>
<li><strong>Risk analysis</strong>: Fat-tailed return distributions</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of time steps.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter in (0, 1).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mu</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Drift coefficient (annualized return).</p>
              </div>
            </td>
            <td>
                  <code>0.05</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Volatility coefficient (annualized).</p>
              </div>
            </td>
            <td>
                  <code>0.2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>t_max</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total time horizon.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>s0</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial price.</p>
              </div>
            </td>
            <td>
                  <code>100.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch dimensions for multiple paths.</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method ('davies_harte' or 'cholesky').</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computation device.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for tensors.</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor of shape <code>(*size, n+1)</code> containing price paths.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If n &lt;= 0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.processes.geometric_fbm--simulate-1-year-of-daily-prices">Simulate 1 year of daily prices</h4>
<p>prices = geometric_fbm(
...     n=252, H=0.6, mu=0.08, sigma=0.20, s0=100.0
... )</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/processes.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="k">def</span><span class="w"> </span><span class="nf">geometric_fbm</span><span class="p">(</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">mu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="n">t_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="n">s0</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.0</span><span class="p">,</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="p">):</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulate Geometric Fractional Brownian Motion (GFBm).</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    Generalization of Geometric Brownian Motion with long-range dependence.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">    Based on the framework described in Rogers (1997).</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">    The price follows:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">    $$S_t = S_0 \\exp\\left((\\mu - \\frac{1}{2}\\sigma^2)t + \\sigma B^H_t\\right)$$</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    where:</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">    - $S_0$ is the initial price</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">    - $\\mu$ is the drift (expected return)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">    - $\\sigma$ is the volatility</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">    - $B^H_t$ is fractional Brownian motion</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">        Unlike standard GBM, GFBm with $H \\neq 0.5$ admits arbitrage in</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">        continuous time. However, it remains useful for modeling observed</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">        market properties like volatility clustering and trend persistence.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    Applications:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">        - **Finance**: Modeling assets with trending behavior ($H &gt; 0.5$)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">        - **Volatility modeling**: Capturing long-memory in volatility</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        - **Risk analysis**: Fat-tailed return distributions</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        n: Number of time steps.</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">        H: Hurst parameter in (0, 1).</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        mu: Drift coefficient (annualized return).</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        sigma: Volatility coefficient (annualized).</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">        t_max: Total time horizon.</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">        s0: Initial price.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        size: Batch dimensions for multiple paths.</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">        method: Generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">        device: Computation device.</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">        dtype: Data type for tensors.</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">        return_numpy: If True, returns NumPy array.</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        Tensor of shape ``(*size, n+1)`` containing price paths.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">        ValueError: If n &lt;= 0.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        &gt;&gt;&gt; # Simulate 1 year of daily prices</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        &gt;&gt;&gt; prices = geometric_fbm(</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        ...     n=252, H=0.6, mu=0.08, sigma=0.20, s0=100.0</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n must be a positive integer&quot;</span><span class="p">)</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">t_max</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="c1"># Generate fBm path and scale to time horizon t_max</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="n">fbm_path</span> <span class="o">=</span> <span class="n">fbm</span><span class="p">(</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="p">)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="n">scale_factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">t_max</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">**</span> <span class="n">H</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="n">fbm_path</span> <span class="o">=</span> <span class="n">fbm_path</span> <span class="o">*</span> <span class="n">scale_factor</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="c1"># Apply exponential transformation</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="n">drift</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="n">diffusion</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">fbm_path</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="n">log_returns</span> <span class="o">=</span> <span class="n">drift</span> <span class="o">+</span> <span class="n">diffusion</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">s0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_returns</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.processes.multifractal_random_walk" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">multifractal_random_walk</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">lambda_sq</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Simulate a Multifractal Random Walk (MRW).</p>
<p>Based on Bacry, Delour &amp; Muzy (2001).</p>
<p>The MRW combines fractional noise with stochastic volatility to produce
multifractal scaling:</p>
<div class="arithmatex">\[X_t = \sum_{i=1}^{t} \sigma_i \epsilon_i\]</div>
<p>where the volatility is:</p>
<div class="arithmatex">\[\sigma_t = \exp(\lambda^2 \omega_t)\]</div>
<p>and <span class="arithmatex">\(\omega_t\)</span> is fGn with Hurst parameter <span class="arithmatex">\(H\)</span>, <span class="arithmatex">\(\epsilon_t\)</span> is Gaussian noise.</p>
<p>The intermittency parameter <span class="arithmatex">\(\lambda^2\)</span> controls the strength of
volatility clustering:
- <span class="arithmatex">\(\lambda^2 \approx 0\)</span>: Nearly Gaussian returns
- <span class="arithmatex">\(\lambda^2 &gt; 0\)</span>: Fat tails and volatility clustering
- Higher <span class="arithmatex">\(\lambda^2\)</span>: More extreme events ("flash crashes")</p>


<details class="properties" open>
  <summary>Properties</summary>
  <ul>
<li>Multifractal spectrum depends on both <span class="arithmatex">\(H\)</span> and <span class="arithmatex">\(\lambda^2\)</span></li>
<li>Captures stylized facts of financial returns</li>
<li>Long-memory in squared/absolute returns</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of time steps.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter for the volatility process.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lambda_sq</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Intermittency coefficient (controls tail fatness).</p>
              </div>
            </td>
            <td>
                  <code>0.02</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computation device.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor of shape <code>(n,)</code> containing the MRW path.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.processes.multifractal_random_walk--simulate-returns-with-volatility-clustering">Simulate returns with volatility clustering</h4>
<p>mrw = multifractal_random_walk(1000, H=0.7, lambda_sq=0.02)</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/processes.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-451" name="__codelineno-0-451"></a><span class="k">def</span><span class="w"> </span><span class="nf">multifractal_random_walk</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">lambda_sq</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulate a Multifractal Random Walk (MRW).</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a><span class="sd">    Based on Bacry, Delour &amp; Muzy (2001).</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a><span class="sd">    The MRW combines fractional noise with stochastic volatility to produce</span>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a><span class="sd">    multifractal scaling:</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a><span class="sd">    $$X_t = \\sum_{i=1}^{t} \\sigma_i \\epsilon_i$$</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a><span class="sd">    where the volatility is:</span>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a><span class="sd">    $$\\sigma_t = \\exp(\\lambda^2 \\omega_t)$$</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a><span class="sd">    and $\\omega_t$ is fGn with Hurst parameter $H$, $\\epsilon_t$ is Gaussian noise.</span>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a>
<a id="__codelineno-0-467" name="__codelineno-0-467"></a><span class="sd">    The intermittency parameter $\\lambda^2$ controls the strength of</span>
<a id="__codelineno-0-468" name="__codelineno-0-468"></a><span class="sd">    volatility clustering:</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a><span class="sd">    - $\\lambda^2 \\approx 0$: Nearly Gaussian returns</span>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a><span class="sd">    - $\\lambda^2 &gt; 0$: Fat tails and volatility clustering</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a><span class="sd">    - Higher $\\lambda^2$: More extreme events (&quot;flash crashes&quot;)</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a><span class="sd">    Properties:</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a><span class="sd">        - Multifractal spectrum depends on both $H$ and $\\lambda^2$</span>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a><span class="sd">        - Captures stylized facts of financial returns</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a><span class="sd">        - Long-memory in squared/absolute returns</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a><span class="sd">        n: Number of time steps.</span>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a><span class="sd">        H: Hurst parameter for the volatility process.</span>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="sd">        lambda_sq: Intermittency coefficient (controls tail fatness).</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="sd">        device: Computation device.</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">        Tensor of shape ``(n,)`` containing the MRW path.</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a><span class="sd">        &gt;&gt;&gt; # Simulate returns with volatility clustering</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a><span class="sd">        &gt;&gt;&gt; mrw = multifractal_random_walk(1000, H=0.7, lambda_sq=0.02)</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a>    <span class="c1"># 1. Generate fGn for the volatility cone (omega)</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a>    <span class="c1"># The correlation of omega is logarithmic</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>    <span class="c1"># This is complex to do perfectly, but a proxy is:</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a>    <span class="n">omega</span> <span class="o">=</span> <span class="n">generate_davies_harte</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a>    <span class="c1"># 2. Stochastic Volatility</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>    <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lambda_sq</span> <span class="o">*</span> <span class="n">omega</span><span class="p">)</span>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a>    <span class="c1"># 3. The Walk</span>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a>    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-501" name="__codelineno-0-501"></a>    <span class="n">mrw</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">noise</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-502" name="__codelineno-0-502"></a>    <span class="k">return</span> <span class="n">mrw</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.processes.reflected_fbm" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reflected_fbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">t_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">start_val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;davies_harte&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Simulate Reflected Fractional Brownian Motion with barriers.</p>
<p>Based on the Skorokhod reflection map applied to fBm increments.</p>
<p>The process is constrained to the interval <span class="arithmatex">\([lower, upper]\)</span> using
instantaneous reflection at the boundaries. This is a continuous-path
approximation of bounded diffusion.</p>


<details class="applications" open>
  <summary>Applications</summary>
  <ul>
<li><strong>Target zone models</strong>: Exchange rates within currency bands
  (Krugman, 1991)</li>
<li><strong>Physical systems</strong>: Particles confined in a box</li>
<li><strong>Finance</strong>: Assets with hard support/resistance levels</li>
<li><strong>Queueing theory</strong>: Buffer capacities</li>
</ul>
</details>

<details class="algorithm" open>
  <summary>Algorithm</summary>
  <ol>
<li>Generate free fBm increments</li>
<li>Apply reflection at each time step using the Skorokhod map</li>
<li>Use JIT compilation for efficiency</li>
</ol>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of time steps.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter in (0, 1).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lower</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lower reflection barrier.</p>
              </div>
            </td>
            <td>
                  <code>-1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>upper</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Upper reflection barrier.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mu</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Drift coefficient.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Volatility coefficient.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>t_max</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total time horizon.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>start_val</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial value (must be in [lower, upper]).</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Batch dimensions.</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method ('davies_harte' or 'cholesky').</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computation device.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor of shape <code>(*size, n+1)</code> with paths bounded in [lower, upper].</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If n &lt;= 0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.processes.reflected_fbm--exchange-rate-in-a-target-zone">Exchange rate in a target zone</h4>
<p>rate = reflected_fbm(
...     n=1000, H=0.7, lower=1.0, upper=1.5, start_val=1.25
... )</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/processes.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-259" name="__codelineno-0-259"></a><span class="k">def</span><span class="w"> </span><span class="nf">reflected_fbm</span><span class="p">(</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>    <span class="n">lower</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>    <span class="n">upper</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>    <span class="n">mu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>    <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>    <span class="n">t_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>    <span class="n">start_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>    <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>    <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>    <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="p">):</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulate Reflected Fractional Brownian Motion with barriers.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">    Based on the Skorokhod reflection map applied to fBm increments.</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">    The process is constrained to the interval $[lower, upper]$ using</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="sd">    instantaneous reflection at the boundaries. This is a continuous-path</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a><span class="sd">    approximation of bounded diffusion.</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="sd">    Applications:</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="sd">        - **Target zone models**: Exchange rates within currency bands</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">          (Krugman, 1991)</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="sd">        - **Physical systems**: Particles confined in a box</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">        - **Finance**: Assets with hard support/resistance levels</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">        - **Queueing theory**: Buffer capacities</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">    Algorithm:</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">        1. Generate free fBm increments</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="sd">        2. Apply reflection at each time step using the Skorokhod map</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="sd">        3. Use JIT compilation for efficiency</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">        n: Number of time steps.</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">        H: Hurst parameter in (0, 1).</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">        lower: Lower reflection barrier.</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">        upper: Upper reflection barrier.</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">        mu: Drift coefficient.</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">        sigma: Volatility coefficient.</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a><span class="sd">        t_max: Total time horizon.</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">        start_val: Initial value (must be in [lower, upper]).</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="sd">        size: Batch dimensions.</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">        method: Generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="sd">        device: Computation device.</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">        return_numpy: If True, returns NumPy array.</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">        Tensor of shape ``(*size, n+1)`` with paths bounded in [lower, upper].</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a><span class="sd">        ValueError: If n &lt;= 0.</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a><span class="sd">        &gt;&gt;&gt; # Exchange rate in a target zone</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a><span class="sd">        &gt;&gt;&gt; rate = reflected_fbm(</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a><span class="sd">        ...     n=1000, H=0.7, lower=1.0, upper=1.5, start_val=1.25</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n must be a positive integer&quot;</span><span class="p">)</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>    <span class="c1"># 1. Generate fGn (Increments)</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>    <span class="c1"># We use fbm() to handle method/clamping, but we need the *steps*, not the path.</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>    <span class="c1"># So we call the generator directly or diff the fbm path.</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>    <span class="c1"># Let&#39;s diff the fbm path for consistency with the geometric_fbm scaling logic.</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>    <span class="c1"># Generate unbounded path first to get correctly scaled increments</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>    <span class="n">unbounded_path</span> <span class="o">=</span> <span class="n">fbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>    <span class="c1"># Scale to t_max and sigma</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>    <span class="n">scale_factor</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="p">(</span><span class="n">t_max</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">**</span> <span class="n">H</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>    <span class="n">unbounded_path</span> <span class="o">=</span> <span class="n">unbounded_path</span> <span class="o">*</span> <span class="n">scale_factor</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>    <span class="c1"># Add drift (mu * dt)</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>    <span class="n">dt</span> <span class="o">=</span> <span class="n">t_max</span> <span class="o">/</span> <span class="n">n</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>    <span class="n">t_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">t_max</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>    <span class="n">drift</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">t_grid</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>    <span class="c1"># Combine to get the proposed increments with drift</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>    <span class="n">total_unbounded</span> <span class="o">=</span> <span class="n">unbounded_path</span> <span class="o">+</span> <span class="n">drift</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>    <span class="c1"># Calculate increments (dX)</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>    <span class="n">increments</span> <span class="o">=</span> <span class="n">total_unbounded</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">total_unbounded</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>    <span class="c1"># 2. Prepare container</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>    <span class="n">reflected_path</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">total_unbounded</span><span class="p">)</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>    <span class="n">reflected_path</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">start_val</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>    <span class="c1"># 3. Run JIT Reflection</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>    <span class="c1"># Ensure bounds are floats for JIT</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>    <span class="n">reflected_path</span> <span class="o">=</span> <span class="n">_apply_reflection</span><span class="p">(</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>        <span class="n">reflected_path</span><span class="p">,</span> <span class="n">increments</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">lower</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="n">upper</span><span class="p">)</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>    <span class="p">)</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>    <span class="k">return</span> <span class="n">reflected_path</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">reflected_path</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="transforms">Transforms</h2>
<p>Fractional calculus transforms (differentiation and integration).</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.transforms" class="doc doc-heading">
            <code>torchfbm.transforms</code>


</h2>

    <div class="doc doc-contents first">

        <p>Fractional calculus transforms for time series.</p>
<p>This module provides fractional differentiation and integration operators,
which generalize classical calculus to non-integer orders.</p>
<p>Based on Grnwald-Letnikov fractional derivatives, implemented via FFT
for computational efficiency.</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.transforms import fractional_diff, fractional_integrate
x = torch.randn(100)
x_diff = fractional_diff(x, d=0.5)  # Half-derivative
x_int = fractional_integrate(x, d=0.5)  # Half-integral</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.transforms.fractional_diff" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fractional_diff</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute the fractional derivative (or integral) of a time series.</p>
<p>Based on the Grnwald-Letnikov definition, implemented via FFT.</p>
<p>The fractional derivative of order <span class="arithmatex">\(d\)</span> is computed in the frequency domain
using the transfer function:</p>
<div class="arithmatex">\[H(\omega) = (1 - e^{-i\omega})^d\]</div>
<p>This generalizes the standard difference operator:
- <span class="arithmatex">\(d = 0\)</span>: Identity (no change)
- <span class="arithmatex">\(d = 1\)</span>: First difference <span class="arithmatex">\(\Delta x_t = x_t - x_{t-1}\)</span>
- <span class="arithmatex">\(d = 0.5\)</span>: Half-derivative (between identity and first difference)
- <span class="arithmatex">\(d &lt; 0\)</span>: Fractional integration (smoothing)</p>


<details class="applications" open>
  <summary>Applications</summary>
  <ul>
<li><strong>Finance</strong>: Fractionally differenced series for ARFIMA models</li>
<li><strong>Memory preservation</strong>: Unlike integer differencing, fractional
  differencing preserves long-range dependence while achieving
  stationarity.</li>
</ul>
</details>

<details class="note" open>
  <summary>Note</summary>
  <p>Uses circular (periodic) boundary conditions due to FFT. Edge effects
may occur at the boundaries.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor. Differentiation applied along <code>dim</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>d</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fractional order. Positive for differentiation, negative for integration.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension along which to apply the transform. Default is last dim.</p>
              </div>
            </td>
            <td>
                  <code>-1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fractionally differentiated tensor with same shape as input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If dimension is invalid or empty.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="TypeError">TypeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If input dtype is not a float type.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>x = torch.cumsum(torch.randn(1000), dim=0)  # Random walk
x_stationary = fractional_diff(x, d=0.4)  # Make stationary</p>
<h4 id="torchfbm.transforms.fractional_diff--x_stationary-should-have-lower-autocorrelation">x_stationary should have lower autocorrelation</h4>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/transforms.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="k">def</span><span class="w"> </span><span class="nf">fractional_diff</span><span class="p">(</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the fractional derivative (or integral) of a time series.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    Based on the Grnwald-Letnikov definition, implemented via FFT.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    The fractional derivative of order $d$ is computed in the frequency domain</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    using the transfer function:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    $$H(\\omega) = (1 - e^{-i\\omega})^d$$</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    This generalizes the standard difference operator:</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    - $d = 0$: Identity (no change)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    - $d = 1$: First difference $\\Delta x_t = x_t - x_{t-1}$</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    - $d = 0.5$: Half-derivative (between identity and first difference)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    - $d &lt; 0$: Fractional integration (smoothing)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    Applications:</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">        - **Finance**: Fractionally differenced series for ARFIMA models</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        - **Memory preservation**: Unlike integer differencing, fractional</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">          differencing preserves long-range dependence while achieving</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">          stationarity.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        Uses circular (periodic) boundary conditions due to FFT. Edge effects</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        may occur at the boundaries.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        x: Input tensor. Differentiation applied along `dim`.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        d: Fractional order. Positive for differentiation, negative for integration.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        dim: Dimension along which to apply the transform. Default is last dim.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        return_numpy: If True, returns NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        Fractionally differentiated tensor with same shape as input.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        ValueError: If dimension is invalid or empty.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        TypeError: If input dtype is not a float type.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        &gt;&gt;&gt; x = torch.cumsum(torch.randn(1000), dim=0)  # Random walk</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        &gt;&gt;&gt; x_stationary = fractional_diff(x, d=0.4)  # Make stationary</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        &gt;&gt;&gt; # x_stationary should have lower autocorrelation</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="n">dim</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">dim</span> <span class="o">&gt;=</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">():</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid dim </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> for input with </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2"> dims&quot;</span><span class="p">)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>            <span class="s2">&quot;Cannot compute fractional difference along an empty dimension&quot;</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="n">real_dtype</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_complex</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="k">if</span> <span class="n">real_dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">):</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported dtype </span><span class="si">{</span><span class="n">real_dtype</span><span class="si">}</span><span class="s2"> for fractional_diff&quot;</span><span class="p">)</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="c1"># Frequency domain transfer function: (1 - e^(-i*omega))^d</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="n">freq_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">promote_types</span><span class="p">(</span><span class="n">real_dtype</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">freq_dtype</span><span class="p">)</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="n">omega</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">freq_dtype</span><span class="p">)</span> <span class="o">*</span> <span class="n">k</span> <span class="o">/</span> <span class="n">n</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="n">transfer</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="n">omega</span><span class="p">))</span> <span class="o">**</span> <span class="n">d</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="n">transfer</span> <span class="o">=</span> <span class="n">transfer</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="n">transfer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">transfer</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="n">view_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="n">view_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="n">transfer</span> <span class="o">=</span> <span class="n">transfer</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">view_shape</span><span class="p">)</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="c1"># Apply via FFT convolution</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="n">x_fft</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="n">transfer</span> <span class="o">=</span> <span class="n">transfer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x_fft</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="n">diff_fft</span> <span class="o">=</span> <span class="n">x_fft</span> <span class="o">*</span> <span class="n">transfer</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="n">x_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft</span><span class="p">(</span><span class="n">diff_fft</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">real</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="k">return</span> <span class="n">x_diff</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">return_numpy</span> <span class="k">else</span> <span class="n">x_diff</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.transforms.fractional_integrate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fractional_integrate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Compute the fractional integral of a time series.</p>
<p>This is the inverse operation of fractional differentiation:</p>
<div class="arithmatex">\[I^d[x] = D^{-d}[x]\]</div>
<p>Fractional integration "smooths" the series by accumulating past values
with power-law decaying weights.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor. Integration applied along <code>dim</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>d</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fractional order of integration (positive values).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dim</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension along which to apply the transform.</p>
              </div>
            </td>
            <td>
                  <code>-1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy array instead of torch.Tensor.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fractionally integrated tensor with same shape as input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>noise = torch.randn(1000)
smooth = fractional_integrate(noise, d=0.5)</p>
<h4 id="torchfbm.transforms.fractional_integrate--smooth-has-longer-memory-than-noise">smooth has longer memory than noise</h4>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/transforms.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="k">def</span><span class="w"> </span><span class="nf">fractional_integrate</span><span class="p">(</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_numpy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the fractional integral of a time series.</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">    This is the inverse operation of fractional differentiation:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">    $$I^d[x] = D^{-d}[x]$$</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">    Fractional integration &quot;smooths&quot; the series by accumulating past values</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">    with power-law decaying weights.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">        x: Input tensor. Integration applied along `dim`.</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">        d: Fractional order of integration (positive values).</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">        dim: Dimension along which to apply the transform.</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">        return_numpy: If True, returns NumPy array instead of torch.Tensor.</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">        Fractionally integrated tensor with same shape as input.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        &gt;&gt;&gt; noise = torch.randn(1000)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">        &gt;&gt;&gt; smooth = fractional_integrate(noise, d=0.5)</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">        &gt;&gt;&gt; # smooth has longer memory than noise</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>    <span class="k">return</span> <span class="n">fractional_diff</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">d</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">return_numpy</span><span class="o">=</span><span class="n">return_numpy</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="layers">Layers</h2>
<p>PyTorch neural network layers with fBm integration.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.layers" class="doc doc-heading">
            <code>torchfbm.layers</code>


</h2>

    <div class="doc doc-contents first">

        <p>Neural network layers with fractional Brownian motion integration.</p>
<p>This module provides PyTorch layers that incorporate fractional Brownian motion
and fractional Gaussian noise for exploration, regularization, and feature
extraction in deep learning.</p>


<details class="layers-included" open>
  <summary>Layers Included</summary>
  <ul>
<li>:class:<code>FBMNoisyLinear</code>: NoisyNet-style linear layer with fBm noise</li>
<li>:class:<code>FractionalPositionalEmbedding</code>: Positional encoding using fBm paths</li>
<li>:class:<code>FractionalKernel</code>: Power-law covariance kernel for attention/GPs</li>
<li>:func:<code>fractional_init_</code>: Weight initialization with correlated noise</li>
</ul>
</details>

<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.layers import FBMNoisyLinear, FractionalPositionalEmbedding
layer = FBMNoisyLinear(64, 32, H=0.7)
pos_embed = FractionalPositionalEmbedding(max_len=512, d_model=256)</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="torchfbm.layers.FBMNoisyLinear" class="doc doc-heading">
            <code>FBMNoisyLinear</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Linear layer with parametric fractional Brownian motion noise.</p>
<p>Based on Fortunato, Azar, Piot et al. (2017) NoisyNets, extended with
fractional Gaussian noise for temporally correlated exploration.</p>
<p>Standard NoisyNets use independent Gaussian noise, which provides
memoryless exploration. This layer uses fGn instead, allowing:
- <strong>H &gt; 0.5</strong>: Persistent exploration (smooth, trending noise)
- <strong>H = 0.5</strong>: Standard NoisyNet behavior (independent noise)
- <strong>H &lt; 0.5</strong>: Anti-persistent exploration (rough, oscillating noise)</p>
<p>The noisy weights are computed as:</p>
<div class="arithmatex">\[W = \mu_W + \sigma_W \odot \epsilon_W\]</div>
<div class="arithmatex">\[b = \mu_b + \sigma_b \odot \epsilon_b\]</div>
<p>where <span class="arithmatex">\(\epsilon_W\)</span> and <span class="arithmatex">\(\epsilon_b\)</span> are sampled from correlated
fGn streams.</p>


<details class="memory-optimization" open>
  <summary>Memory Optimization</summary>
  <p>For large layers, full-rank noise requires <span class="arithmatex">\(O(n_{out} \times n_{in})\)</span>
storage. The <code>rank</code> parameter enables low-rank factorization:
- <code>rank='full'</code>: Independent noise per weight (expensive)
- <code>rank=k</code>: Uses <span class="arithmatex">\(k\)</span> rank-1 outer products (efficient)</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>in_features</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of input features.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>out_features</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of output features.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter for fBm noise (0 &lt; H &lt; 1).</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma_init</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial scale for learnable noise parameters.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rank</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="int">int</span>, <span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Noise rank ('full' for independent, or integer for low-rank).</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>buffer_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of pre-generated noise samples.</p>
              </div>
            </td>
            <td>
                  <code>1000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method ('davies_harte' or 'cholesky').</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device to store parameters and buffers.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for parameters and buffers.</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for reproducibility.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.layers.FBMNoisyLinear--replace-standard-linear-in-dqn-for-exploration">Replace standard linear in DQN for exploration</h4>
<p>layer = FBMNoisyLinear(64, 32, H=0.7, rank=4)
layer.train()  # Noisy weights during training
output = layer(input)
layer.eval()   # Mean weights during inference
output = layer(input)</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="k">class</span><span class="w"> </span><span class="nc">FBMNoisyLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Linear layer with parametric fractional Brownian motion noise.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    Based on Fortunato, Azar, Piot et al. (2017) NoisyNets, extended with</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    fractional Gaussian noise for temporally correlated exploration.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">    Standard NoisyNets use independent Gaussian noise, which provides</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    memoryless exploration. This layer uses fGn instead, allowing:</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">    - **H &gt; 0.5**: Persistent exploration (smooth, trending noise)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    - **H = 0.5**: Standard NoisyNet behavior (independent noise)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    - **H &lt; 0.5**: Anti-persistent exploration (rough, oscillating noise)</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    The noisy weights are computed as:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">    $$W = \\mu_W + \\sigma_W \\odot \\epsilon_W$$</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    $$b = \\mu_b + \\sigma_b \\odot \\epsilon_b$$</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    where $\\epsilon_W$ and $\\epsilon_b$ are sampled from correlated</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    fGn streams.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    Memory Optimization:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        For large layers, full-rank noise requires $O(n_{out} \\times n_{in})$</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        storage. The ``rank`` parameter enables low-rank factorization:</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        - ``rank=&#39;full&#39;``: Independent noise per weight (expensive)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        - ``rank=k``: Uses $k$ rank-1 outer products (efficient)</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        in_features: Number of input features.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        out_features: Number of output features.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        H: Hurst parameter for fBm noise (0 &lt; H &lt; 1).</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        sigma_init: Initial scale for learnable noise parameters.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        rank: Noise rank (&#39;full&#39; for independent, or integer for low-rank).</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        buffer_size: Number of pre-generated noise samples.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        method: Generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        device: Device to store parameters and buffers.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        dtype: Data type for parameters and buffers.</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        seed: Random seed for reproducibility.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">        &gt;&gt;&gt; # Replace standard linear in DQN for exploration</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">        &gt;&gt;&gt; layer = FBMNoisyLinear(64, 32, H=0.7, rank=4)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">        &gt;&gt;&gt; layer.train()  # Noisy weights during training</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        &gt;&gt;&gt; output = layer(input)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">        &gt;&gt;&gt; layer.eval()   # Mean weights during inference</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">        &gt;&gt;&gt; output = layer(input)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="n">H</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="n">sigma_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">rank</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># 1, 10, or &quot;full&quot;</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="p">):</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">H</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">dtype</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">=</span> <span class="n">seed</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="c1"># --- Learnable Parameters ---</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="p">)</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight_sigma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="p">)</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="p">)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias_sigma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="p">)</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>        <span class="c1"># --- Output Buffers (for sampled noise) ---</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>            <span class="s2">&quot;weight_epsilon&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>            <span class="s2">&quot;bias_epsilon&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="p">)</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="c1"># --- Stream Buffers (The reservoir of random numbers) ---</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="c1"># 1. Bias is ALWAYS independent (Full Rank) because it&#39;s cheap (O(N))</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>            <span class="s2">&quot;noise_bias&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="c1"># 2. Weight Noise Allocation</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>            <span class="c1"># Independent: O(N_out * N_in) - Expensive</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>                <span class="s2">&quot;noise_weight_source&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>            <span class="k">if</span> <span class="p">(</span><span class="n">in_features</span> <span class="o">*</span> <span class="n">out_features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e9</span><span class="p">:</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>                <span class="nb">print</span><span class="p">(</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>                    <span class="sa">f</span><span class="s2">&quot;Warning: Using full-rank noise for weights with size &quot;</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>                    <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">out_features</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">in_features</span><span class="si">}</span><span class="s2">) may consume significant memory. Consider setting rank to a smaller integer.&quot;</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>                <span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>            <span class="c1"># Low-Rank: O(Rank * (N_out + N_in)) memory - Efficient</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">r</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>                <span class="s2">&quot;noise_in&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>            <span class="p">)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>                <span class="s2">&quot;noise_out&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>            <span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">(</span><span class="n">sigma_init</span><span class="p">)</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">refresh_noise_stream</span><span class="p">()</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma_init</span><span class="p">):</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize layer parameters.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        Uses uniform initialization for mean parameters and constant</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        initialization for sigma parameters.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">            sigma_init: Initial value for noise scaling parameters.</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="n">mu_range</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="o">**</span><span class="mf">0.5</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">mu_range</span><span class="p">,</span> <span class="n">mu_range</span><span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight_sigma</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">sigma_init</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">mu_range</span><span class="p">,</span> <span class="n">mu_range</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias_sigma</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">sigma_init</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">refresh_noise_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Regenerate the fGn noise buffers.</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        Called automatically when the buffer is exhausted during forward passes.</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">        Uses different seeds for weight and bias noise to ensure independence.</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_cholesky</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;cholesky&quot;</span> <span class="k">else</span> <span class="n">generate_davies_harte</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="c1"># --- Seed Management ---</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>        <span class="c1"># We ensure distinct seeds for every component to prevent correlation</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="n">s_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="n">s_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="n">s_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="n">s_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">+</span> <span class="mi">3</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="c1"># 1. Generate Bias Noise (Always Independent)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">noise_bias</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,),</span> 
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_bias</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="c1"># 2. Generate Weight Noise</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>            <span class="c1"># Flatten, generate, reshape</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>            <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>            <span class="n">raw</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">total</span><span class="p">,),</span> 
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_full</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>            <span class="p">)</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">noise_weight_source</span> <span class="o">=</span> <span class="n">raw</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>            <span class="n">r</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>            <span class="c1"># Input Factors (Rank, In)</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>            <span class="n">noise_in_flat</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">r</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,),</span> 
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_in</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>            <span class="p">)</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">noise_in</span> <span class="o">=</span> <span class="n">noise_in_flat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>            <span class="c1"># Output Factors (Rank, Out)</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>            <span class="n">noise_out_flat</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">r</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,),</span> 
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_out</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>            <span class="p">)</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">noise_out</span> <span class="o">=</span> <span class="n">noise_out_flat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">sample_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample noise for current forward pass.</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a><span class="sd">        Reads from pre-generated buffers and constructs weight/bias noise.</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">        For low-rank mode, synthesizes full noise matrix from rank-k factors.</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">:</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">refresh_noise_stream</span><span class="p">()</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>        <span class="c1"># Bias is always simple lookup</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias_epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_bias</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weight_epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_weight_source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>            <span class="c1"># Low-Rank Synthesis</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>            <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_in</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>   <span class="c1"># (Rank, In)</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>  <span class="c1"># (Rank, Out)</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>            <span class="c1"># Apply Factorized NoisyNet transform: f(x) = sign(x) * sqrt(abs(x))</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>            <span class="c1"># This preserves the magnitude distribution when multiplying two Gaussians</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>            <span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sqrt</span><span class="p">())</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>            <span class="n">u_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>            <span class="n">v_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>            <span class="c1"># Sum of Outer Products: W = (1/sqrt(K)) * Sum(v_k (x) u_k)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>            <span class="c1"># einsum: rank(r), out(o), in(i) -&gt; out(o), in(i)</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>            <span class="n">matrix_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ro, ri -&gt; oi&#39;</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">,</span> <span class="n">u_hat</span><span class="p">)</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>            <span class="c1"># Scale to maintain unit variance</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>            <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weight_epsilon</span> <span class="o">=</span> <span class="n">matrix_noise</span> <span class="o">*</span> <span class="n">scale</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass with optional noise injection.</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">        During training: Uses noisy weights $\\mu + \\sigma \\odot \\epsilon$</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">        During eval: Uses only mean weights $\\mu$</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">            input: Input tensor of shape ``(batch, in_features)``.</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">            Output tensor of shape ``(batch, out_features)``.</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">sample_noise</span><span class="p">()</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>                <span class="nb">input</span><span class="p">,</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_epsilon</span><span class="p">,</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_epsilon</span><span class="p">,</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>            <span class="p">)</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.layers.FBMNoisyLinear.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Forward pass with optional noise injection.</p>
<p>During training: Uses noisy weights <span class="arithmatex">\(\mu + \sigma \odot \epsilon\)</span>
During eval: Uses only mean weights <span class="arithmatex">\(\mu\)</span></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor of shape <code>(batch, in_features)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Output tensor of shape <code>(batch, out_features)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward pass with optional noise injection.</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">    During training: Uses noisy weights $\\mu + \\sigma \\odot \\epsilon$</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">    During eval: Uses only mean weights $\\mu$</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">        input: Input tensor of shape ``(batch, in_features)``.</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">        Output tensor of shape ``(batch, out_features)``.</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sample_noise</span><span class="p">()</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>            <span class="nb">input</span><span class="p">,</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_epsilon</span><span class="p">,</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_epsilon</span><span class="p">,</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>        <span class="p">)</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="torchfbm.layers.FBMNoisyLinear.refresh_noise_stream" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">refresh_noise_stream</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Regenerate the fGn noise buffers.</p>
<p>Called automatically when the buffer is exhausted during forward passes.
Uses different seeds for weight and bias noise to ensure independence.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="k">def</span><span class="w"> </span><span class="nf">refresh_noise_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Regenerate the fGn noise buffers.</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">    Called automatically when the buffer is exhausted during forward passes.</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">    Uses different seeds for weight and bias noise to ensure independence.</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_cholesky</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;cholesky&quot;</span> <span class="k">else</span> <span class="n">generate_davies_harte</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="c1"># --- Seed Management ---</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="c1"># We ensure distinct seeds for every component to prevent correlation</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="n">s_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="n">s_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="n">s_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="n">s_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">+</span> <span class="mi">3</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="c1"># 1. Generate Bias Noise (Always Independent)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">noise_bias</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,),</span> 
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_bias</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="c1"># 2. Generate Weight Noise</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="c1"># Flatten, generate, reshape</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>        <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="n">raw</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">total</span><span class="p">,),</span> 
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_full</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>        <span class="p">)</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">noise_weight_source</span> <span class="o">=</span> <span class="n">raw</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>        <span class="n">r</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="c1"># Input Factors (Rank, In)</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>        <span class="n">noise_in_flat</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">r</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,),</span> 
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_in</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>        <span class="p">)</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">noise_in</span> <span class="o">=</span> <span class="n">noise_in_flat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>        <span class="c1"># Output Factors (Rank, Out)</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>        <span class="n">noise_out_flat</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="p">(</span><span class="n">r</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,),</span> 
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">s_out</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>        <span class="p">)</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">noise_out</span> <span class="o">=</span> <span class="n">noise_out_flat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="torchfbm.layers.FBMNoisyLinear.reset_parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset_parameters</span><span class="p">(</span><span class="n">sigma_init</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize layer parameters.</p>
<p>Uses uniform initialization for mean parameters and constant
initialization for sigma parameters.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>sigma_init</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial value for noise scaling parameters.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma_init</span><span class="p">):</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize layer parameters.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">    Uses uniform initialization for mean parameters and constant</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">    initialization for sigma parameters.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">        sigma_init: Initial value for noise scaling parameters.</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="n">mu_range</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="o">**</span><span class="mf">0.5</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">mu_range</span><span class="p">,</span> <span class="n">mu_range</span><span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">weight_sigma</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">sigma_init</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">mu_range</span><span class="p">,</span> <span class="n">mu_range</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">bias_sigma</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">sigma_init</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="torchfbm.layers.FBMNoisyLinear.sample_noise" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample_noise</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Sample noise for current forward pass.</p>
<p>Reads from pre-generated buffers and constructs weight/bias noise.
For low-rank mode, synthesizes full noise matrix from rank-k factors.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="k">def</span><span class="w"> </span><span class="nf">sample_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample noise for current forward pass.</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a><span class="sd">    Reads from pre-generated buffers and constructs weight/bias noise.</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a><span class="sd">    For low-rank mode, synthesizes full noise matrix from rank-k factors.</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">:</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">refresh_noise_stream</span><span class="p">()</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>    <span class="c1"># Bias is always simple lookup</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">bias_epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_bias</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight_epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_weight_source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>        <span class="c1"># Low-Rank Synthesis</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_in</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>   <span class="c1"># (Rank, In)</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span><span class="p">]</span>  <span class="c1"># (Rank, Out)</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>        <span class="c1"># Apply Factorized NoisyNet transform: f(x) = sign(x) * sqrt(abs(x))</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>        <span class="c1"># This preserves the magnitude distribution when multiplying two Gaussians</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>        <span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sqrt</span><span class="p">())</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>        <span class="n">u_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>        <span class="c1"># Sum of Outer Products: W = (1/sqrt(K)) * Sum(v_k (x) u_k)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="c1"># einsum: rank(r), out(o), in(i) -&gt; out(o), in(i)</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>        <span class="n">matrix_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ro, ri -&gt; oi&#39;</span><span class="p">,</span> <span class="n">v_hat</span><span class="p">,</span> <span class="n">u_hat</span><span class="p">)</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>        <span class="c1"># Scale to maintain unit variance</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight_epsilon</span> <span class="o">=</span> <span class="n">matrix_noise</span> <span class="o">*</span> <span class="n">scale</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="torchfbm.layers.FractionalKernel" class="doc doc-heading">
            <code>FractionalKernel</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Power-law covariance kernel based on fractional distance.</p>
<p>Computes similarity based on the fractional Brownian motion covariance
structure, where correlation decays as a power law with distance.</p>
<p>The kernel is defined as:</p>
<div class="arithmatex">\[K(x, y) = \exp\left(-\left(\frac{\|x - y\|}{\ell}\right)^{2H}\right)\]</div>
<p>where:
- <span class="arithmatex">\(\|x - y\|\)</span> is the Euclidean distance
- <span class="arithmatex">\(\ell\)</span> is the length scale
- <span class="arithmatex">\(H\)</span> is the Hurst parameter</p>


<details class="properties" open>
  <summary>Properties</summary>
  <ul>
<li><strong>H = 0.5</strong>: Standard squared exponential (RBF) kernel</li>
<li><strong>H &lt; 0.5</strong>: Rougher kernel (faster decay)</li>
<li><strong>H &gt; 0.5</strong>: Smoother kernel (slower decay)</li>
</ul>
</details>

<details class="applications" open>
  <summary>Applications</summary>
  <ul>
<li><strong>Attention mechanisms</strong>: Fractal-aware attention patterns</li>
<li><strong>Gaussian Processes</strong>: Long-memory covariance functions</li>
<li><strong>Kernel methods</strong>: SVMs with power-law similarity</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter controlling decay rate.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>length_scale</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Characteristic length scale <span class="arithmatex">\(\ell\)</span>.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>kernel = FractionalKernel(H=0.7, length_scale=1.0)
x1 = torch.randn(32, 10, 64)  # (batch, n_points, dim)
x2 = torch.randn(32, 20, 64)  # (batch, m_points, dim)
K = kernel(x1, x2)  # (32, 10, 20) similarity matrix</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-436" name="__codelineno-0-436"></a><span class="k">class</span><span class="w"> </span><span class="nc">FractionalKernel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Power-law covariance kernel based on fractional distance.</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a><span class="sd">    Computes similarity based on the fractional Brownian motion covariance</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a><span class="sd">    structure, where correlation decays as a power law with distance.</span>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a><span class="sd">    The kernel is defined as:</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a><span class="sd">    $$K(x, y) = \\exp\\left(-\\left(\\frac{\\|x - y\\|}{\\ell}\\right)^{2H}\\right)$$</span>
<a id="__codelineno-0-445" name="__codelineno-0-445"></a>
<a id="__codelineno-0-446" name="__codelineno-0-446"></a><span class="sd">    where:</span>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a><span class="sd">    - $\\|x - y\\|$ is the Euclidean distance</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a><span class="sd">    - $\\ell$ is the length scale</span>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a><span class="sd">    - $H$ is the Hurst parameter</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a><span class="sd">    Properties:</span>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a><span class="sd">        - **H = 0.5**: Standard squared exponential (RBF) kernel</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a><span class="sd">        - **H &lt; 0.5**: Rougher kernel (faster decay)</span>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a><span class="sd">        - **H &gt; 0.5**: Smoother kernel (slower decay)</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a><span class="sd">    Applications:</span>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a><span class="sd">        - **Attention mechanisms**: Fractal-aware attention patterns</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a><span class="sd">        - **Gaussian Processes**: Long-memory covariance functions</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a><span class="sd">        - **Kernel methods**: SVMs with power-law similarity</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a><span class="sd">        H: Hurst parameter controlling decay rate.</span>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a><span class="sd">        length_scale: Characteristic length scale $\\ell$.</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a><span class="sd">        &gt;&gt;&gt; kernel = FractionalKernel(H=0.7, length_scale=1.0)</span>
<a id="__codelineno-0-467" name="__codelineno-0-467"></a><span class="sd">        &gt;&gt;&gt; x1 = torch.randn(32, 10, 64)  # (batch, n_points, dim)</span>
<a id="__codelineno-0-468" name="__codelineno-0-468"></a><span class="sd">        &gt;&gt;&gt; x2 = torch.randn(32, 20, 64)  # (batch, m_points, dim)</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a><span class="sd">        &gt;&gt;&gt; K = kernel(x1, x2)  # (32, 10, 20) similarity matrix</span>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">H</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">H</span>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">=</span> <span class="n">length_scale</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute pairwise kernel values.</span>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="sd">            x1: First set of points, shape ``(batch, n, dim)``.</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="sd">            x2: Second set of points, shape ``(batch, m, dim)``.</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">            Kernel matrix of shape ``(batch, n, m)``.</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a>        <span class="c1"># x1: (B, N, D)</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a>        <span class="c1"># x2: (B, M, D)</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a>        <span class="c1"># Compute pairwise distances</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a>        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Euclidean dist</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a>        <span class="c1"># Fractional similarity</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>        <span class="c1"># We invert it so closer = higher similarity</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a>        <span class="c1"># Kernel = exp( - (dist / length_scale)^(2H) )</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">dist</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.layers.FractionalKernel.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Compute pairwise kernel values.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x1</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>First set of points, shape <code>(batch, n, dim)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>x2</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Second set of points, shape <code>(batch, m, dim)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Kernel matrix of shape <code>(batch, n, m)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span>
<span class="normal"><a href="#__codelineno-0-486">486</a></span>
<span class="normal"><a href="#__codelineno-0-487">487</a></span>
<span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-477" name="__codelineno-0-477"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute pairwise kernel values.</span>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a><span class="sd">        x1: First set of points, shape ``(batch, n, dim)``.</span>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a><span class="sd">        x2: Second set of points, shape ``(batch, m, dim)``.</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a><span class="sd">        Kernel matrix of shape ``(batch, n, m)``.</span>
<a id="__codelineno-0-486" name="__codelineno-0-486"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-487" name="__codelineno-0-487"></a>    <span class="c1"># x1: (B, N, D)</span>
<a id="__codelineno-0-488" name="__codelineno-0-488"></a>    <span class="c1"># x2: (B, M, D)</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a>    <span class="c1"># Compute pairwise distances</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a>    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Euclidean dist</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a>    <span class="c1"># Fractional similarity</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>    <span class="c1"># We invert it so closer = higher similarity</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a>    <span class="c1"># Kernel = exp( - (dist / length_scale)^(2H) )</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">dist</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="torchfbm.layers.FractionalPositionalEmbedding" class="doc doc-heading">
            <code>FractionalPositionalEmbedding</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Positional embedding using frozen fractional Brownian motion paths.</p>
<p>Uses diverse fBm paths with varying Hurst parameters to create
positional encodings that capture multi-scale fractal structure.</p>
<p>Unlike sinusoidal embeddings which encode position at fixed frequencies,
fBm embeddings encode position at varying levels of roughness:
- Low H channels: High-frequency, local position information
- High H channels: Low-frequency, global position trends</p>
<p>The embedding is computed once during initialization and frozen
(non-learnable), similar to standard positional encodings.</p>


<details class="algorithm" open>
  <summary>Algorithm</summary>
  <ol>
<li>Generate <code>d_model</code> fBm paths with Hurst parameters
   linearly spaced in <code>H_range</code></li>
<li>Normalize each path to zero mean and unit variance</li>
<li>Store as frozen buffer</li>
</ol>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>max_len</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum sequence length supported.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>d_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension (number of fBm paths).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H_range</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tuple of (H_min, H_max) for diverse roughness levels.</p>
              </div>
            </td>
            <td>
                  <code>(0.1, 0.9)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method ('davies_harte' or 'cholesky').</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device to store embeddings.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for embeddings.</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Random seed for reproducibility.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>embed = FractionalPositionalEmbedding(
...     max_len=512, d_model=256, H_range=(0.1, 0.9)
... )
x = torch.randn(32, 100, 256)  # (batch, seq, dim)
x_with_pos = embed(x)  # Adds positional encoding</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/layers.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="k">class</span><span class="w"> </span><span class="nc">FractionalPositionalEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Positional embedding using frozen fractional Brownian motion paths.</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">    Uses diverse fBm paths with varying Hurst parameters to create</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">    positional encodings that capture multi-scale fractal structure.</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">    Unlike sinusoidal embeddings which encode position at fixed frequencies,</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">    fBm embeddings encode position at varying levels of roughness:</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">    - Low H channels: High-frequency, local position information</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">    - High H channels: Low-frequency, global position trends</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a><span class="sd">    The embedding is computed once during initialization and frozen</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">    (non-learnable), similar to standard positional encodings.</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">    Algorithm:</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="sd">        1. Generate ``d_model`` fBm paths with Hurst parameters</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">           linearly spaced in ``H_range``</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">        2. Normalize each path to zero mean and unit variance</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">        3. Store as frozen buffer</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a><span class="sd">        max_len: Maximum sequence length supported.</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a><span class="sd">        d_model: Embedding dimension (number of fBm paths).</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a><span class="sd">        H_range: Tuple of (H_min, H_max) for diverse roughness levels.</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a><span class="sd">        method: Generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a><span class="sd">        device: Device to store embeddings.</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a><span class="sd">        dtype: Data type for embeddings.</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a><span class="sd">        seed: Random seed for reproducibility.</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a><span class="sd">        &gt;&gt;&gt; embed = FractionalPositionalEmbedding(</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="sd">        ...     max_len=512, d_model=256, H_range=(0.1, 0.9)</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="sd">        &gt;&gt;&gt; x = torch.randn(32, 100, 256)  # (batch, seq, dim)</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="sd">        &gt;&gt;&gt; x_with_pos = embed(x)  # Adds positional encoding</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>        <span class="n">max_len</span><span class="p">,</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>        <span class="n">d_model</span><span class="p">,</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>        <span class="n">H_range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">),</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>    <span class="p">):</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">dtype</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">=</span> <span class="n">seed</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>        <span class="c1"># 1. Create H values from H_range[0] to H_range[1]</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>        <span class="c1"># We ensure they are within safe bounds [0.01, 0.99]</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>        <span class="n">h_min</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">H_range</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>        <span class="n">h_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">H_range</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>        <span class="n">Hs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>            <span class="n">h_min</span><span class="p">,</span> <span class="n">h_max</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>        <span class="p">)</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>        <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d_model</span><span class="p">):</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>            <span class="c1"># Generate path using selected method</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>            <span class="c1"># We generate on CPU initially to save GPU memory for weights,</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>            <span class="c1"># then register as buffer moves it to device automatically.</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>            <span class="n">path</span> <span class="o">=</span> <span class="n">fbm</span><span class="p">(</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>                <span class="n">max_len</span><span class="p">,</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>                <span class="n">H</span><span class="o">=</span><span class="n">Hs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a>                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a>                <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_seed</span><span class="p">,</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>            <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>            <span class="c1"># Normalization (Critical for Embeddings to preserve gradient scale)</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>            <span class="n">path</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span> <span class="o">-</span> <span class="n">path</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>            <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a>        <span class="c1"># Shape: (max_len, d_model)</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a>        <span class="c1"># We assume the fbm path length (max_len+1) needs to be trimmed or matched</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>        <span class="c1"># fbm() returns n+1 points, take 1 to max_len+1</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>        <span class="n">pe_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>        <span class="c1"># Crop if fbm generated n+1 and we want max_len</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>        <span class="n">pe_tensor</span> <span class="o">=</span> <span class="n">pe_tensor</span><span class="p">[:</span><span class="n">max_len</span><span class="p">,</span> <span class="p">:]</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;pe&quot;</span><span class="p">,</span> <span class="n">pe_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">))</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Add positional encoding to input.</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">            x: Input tensor of shape ``(batch, seq_len, d_model)``.</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a><span class="sd">            Tensor with positional encoding added, same shape as input.</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a><span class="sd">            ValueError: If sequence length exceeds ``max_len``.</span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>        <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>                <span class="sa">f</span><span class="s2">&quot;Sequence length </span><span class="si">{</span><span class="n">seq_len</span><span class="si">}</span><span class="s2"> exceeds max_len </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>            <span class="p">)</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.layers.FractionalPositionalEmbedding.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Add positional encoding to input.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor of shape <code>(batch, seq_len, d_model)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor with positional encoding added, same shape as input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If sequence length exceeds <code>max_len</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Add positional encoding to input.</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">        x: Input tensor of shape ``(batch, seq_len, d_model)``.</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a><span class="sd">        Tensor with positional encoding added, same shape as input.</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a><span class="sd">        ValueError: If sequence length exceeds ``max_len``.</span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>    <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>            <span class="sa">f</span><span class="s2">&quot;Sequence length </span><span class="si">{</span><span class="n">seq_len</span><span class="si">}</span><span class="s2"> exceeds max_len </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>        <span class="p">)</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="torchfbm.layers.fractional_init_" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">fractional_init_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Initialize tensor weights using fractional Gaussian noise (in-place).</p>
<p>Fills the tensor with correlated fGn values, inducing long-range
spatial correlations in the weight matrix. May be useful for:
- CNN kernels where adjacent weights should be correlated
- Inducing smoothness priors in weight space
- Experimental architectures with structured initialization</p>
<p>The fGn is normalized to zero mean and scaled to the target standard
deviation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor to initialize (modified in-place).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter controlling spatial correlation.</p>
              </div>
            </td>
            <td>
                  <code>0.7</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>std</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target standard deviation of initialized weights.</p>
              </div>
            </td>
            <td>
                  <code>0.02</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>linear = nn.Linear(64, 32)
fractional_init_(linear.weight, H=0.7, std=0.02)</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/layers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="k">def</span><span class="w"> </span><span class="nf">fractional_init_</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">H</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.02</span><span class="p">):</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize tensor weights using fractional Gaussian noise (in-place).</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a><span class="sd">    Fills the tensor with correlated fGn values, inducing long-range</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a><span class="sd">    spatial correlations in the weight matrix. May be useful for:</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a><span class="sd">    - CNN kernels where adjacent weights should be correlated</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a><span class="sd">    - Inducing smoothness priors in weight space</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a><span class="sd">    - Experimental architectures with structured initialization</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a><span class="sd">    The fGn is normalized to zero mean and scaled to the target standard</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a><span class="sd">    deviation.</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a><span class="sd">        tensor: Tensor to initialize (modified in-place).</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a><span class="sd">        H: Hurst parameter controlling spatial correlation.</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a><span class="sd">        std: Target standard deviation of initialized weights.</span>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a><span class="sd">        &gt;&gt;&gt; linear = nn.Linear(64, 32)</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a><span class="sd">        &gt;&gt;&gt; fractional_init_(linear.weight, H=0.7, std=0.02)</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>        <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>        <span class="n">total_elements</span> <span class="o">=</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>        <span class="c1"># Generate a long correlated stream</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>        <span class="n">fgn</span> <span class="o">=</span> <span class="n">generate_davies_harte</span><span class="p">(</span><span class="n">total_elements</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>        <span class="c1"># Normalize and Scale</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>        <span class="n">fgn</span> <span class="o">=</span> <span class="p">(</span><span class="n">fgn</span> <span class="o">-</span> <span class="n">fgn</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">fgn</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>        <span class="n">fgn</span> <span class="o">=</span> <span class="n">fgn</span> <span class="o">*</span> <span class="n">std</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>        <span class="n">tensor</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">fgn</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="sde">SDE</h2>
<p>Fractional stochastic differential equation solvers.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.sde" class="doc doc-heading">
            <code>torchfbm.sde</code>


</h2>

    <div class="doc doc-contents first">

        <p>Fractional stochastic differential equation solvers.</p>
<p>This module provides neural network modules for solving stochastic
differential equations driven by fractional Brownian motion.</p>
<p>Based on the theory of rough paths and fractional calculus for SDEs.</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.sde import NeuralFSDE
drift = nn.Linear(2, 2)
diffusion = nn.Linear(2, 2)
fsde = NeuralFSDE(state_size=2, drift_net=drift, diffusion_net=diffusion)
x0 = torch.randn(32, 2)
trajectory = fsde(x0, n_steps=100)</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="torchfbm.sde.NeuralFSDE" class="doc doc-heading">
            <code>NeuralFSDE</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Neural network solver for fractional stochastic differential equations.</p>
<p>Solves SDEs of the form:</p>
<div class="arithmatex">\[dX_t = \mu(X_t, t)dt + \sigma(X_t, t)dB^H_t\]</div>
<p>where:
- <span class="arithmatex">\(\mu\)</span> is the drift network
- <span class="arithmatex">\(\sigma\)</span> is the diffusion network
- <span class="arithmatex">\(B^H_t\)</span> is fractional Brownian motion with Hurst parameter <span class="arithmatex">\(H\)</span></p>
<p>Uses Euler-Maruyama discretization with fGn increments. The Hurst
parameter can optionally be learned during training.</p>


<details class="note" open>
  <summary>Note</summary>
  <p>For <span class="arithmatex">\(H &lt; 0.5\)</span> (rough regime), standard Euler-Maruyama may be unstable.
This implementation raises an error for <span class="arithmatex">\(H &lt; 0.5\)</span> until rough path
integration methods are implemented.</p>
</details>

<details class="algorithm" open>
  <summary>Algorithm</summary>
  <p>For each step <span class="arithmatex">\(i\)</span>:</p>
<div class="arithmatex">\[X_{i+1} = X_i + \mu(X_i) \Delta t + \sigma(X_i) \cdot (\Delta t)^H \epsilon_i\]</div>
<p>where <span class="arithmatex">\(\epsilon_i\)</span> is fGn with the specified Hurst parameter.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>state_size</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension of the state space.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drift_net</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neural network for drift <span class="arithmatex">\(\mu(X_t)\)</span>. Input/output: <code>state_size</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>diffusion_net</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neural network for diffusion <span class="arithmatex">\(\sigma(X_t)\)</span>. Input/output: <code>state_size</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H_init</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial Hurst parameter value.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>learnable_H</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, H is a learnable parameter.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>t_max</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total time horizon for integration.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.sde.NeuralFSDE--define-drift-and-diffusion-networks">Define drift and diffusion networks</h4>
<p>drift = nn.Sequential(nn.Linear(2, 16), nn.Tanh(), nn.Linear(16, 2))
diffusion = nn.Sequential(nn.Linear(2, 16), nn.Tanh(), nn.Linear(16, 2))</p>
<h4 id="torchfbm.sde.NeuralFSDE--create-fsde-with-learnable-hurst-parameter">Create fSDE with learnable Hurst parameter</h4>
<p>fsde = NeuralFSDE(
...     state_size=2,
...     drift_net=drift,
...     diffusion_net=diffusion,
...     H_init=0.7,
...     learnable_H=True
... )</p>
<h4 id="torchfbm.sde.NeuralFSDE--integrate-from-initial-conditions">Integrate from initial conditions</h4>
<p>x0 = torch.randn(32, 2)  # Batch of initial states
trajectory = fsde(x0, n_steps=100)  # (32, 101, 2)</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/sde.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="k">class</span><span class="w"> </span><span class="nc">NeuralFSDE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Neural network solver for fractional stochastic differential equations.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    Solves SDEs of the form:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    $$dX_t = \\mu(X_t, t)dt + \\sigma(X_t, t)dB^H_t$$</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    where:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    - $\\mu$ is the drift network</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    - $\\sigma$ is the diffusion network</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    - $B^H_t$ is fractional Brownian motion with Hurst parameter $H$</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    Uses Euler-Maruyama discretization with fGn increments. The Hurst</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    parameter can optionally be learned during training.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        For $H &lt; 0.5$ (rough regime), standard Euler-Maruyama may be unstable.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">        This implementation raises an error for $H &lt; 0.5$ until rough path</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        integration methods are implemented.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    Algorithm:</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        For each step $i$:</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        $$X_{i+1} = X_i + \\mu(X_i) \\Delta t + \\sigma(X_i) \\cdot (\\Delta t)^H \\epsilon_i$$</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        where $\\epsilon_i$ is fGn with the specified Hurst parameter.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        state_size: Dimension of the state space.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        drift_net: Neural network for drift $\\mu(X_t)$. Input/output: ``state_size``.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        diffusion_net: Neural network for diffusion $\\sigma(X_t)$. Input/output: ``state_size``.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        H_init: Initial Hurst parameter value.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        learnable_H: If True, H is a learnable parameter.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        t_max: Total time horizon for integration.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        &gt;&gt;&gt; # Define drift and diffusion networks</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        &gt;&gt;&gt; drift = nn.Sequential(nn.Linear(2, 16), nn.Tanh(), nn.Linear(16, 2))</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        &gt;&gt;&gt; diffusion = nn.Sequential(nn.Linear(2, 16), nn.Tanh(), nn.Linear(16, 2))</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        &gt;&gt;&gt;</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        &gt;&gt;&gt; # Create fSDE with learnable Hurst parameter</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        &gt;&gt;&gt; fsde = NeuralFSDE(</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        ...     state_size=2,</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        ...     drift_net=drift,</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        ...     diffusion_net=diffusion,</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        ...     H_init=0.7,</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        ...     learnable_H=True</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        &gt;&gt;&gt;</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        &gt;&gt;&gt; # Integrate from initial conditions</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        &gt;&gt;&gt; x0 = torch.randn(32, 2)  # Batch of initial states</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">        &gt;&gt;&gt; trajectory = fsde(x0, n_steps=100)  # (32, 101, 2)</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="n">state_size</span><span class="p">,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="n">drift_net</span><span class="p">,</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="n">diffusion_net</span><span class="p">,</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="n">H_init</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="n">learnable_H</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">t_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="p">):</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">state_size</span> <span class="o">=</span> <span class="n">state_size</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">drift_net</span> <span class="o">=</span> <span class="n">drift_net</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">diffusion_net</span> <span class="o">=</span> <span class="n">diffusion_net</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t_max</span> <span class="o">=</span> <span class="n">t_max</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="c1"># Constraint: H must be in (0, 1)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="n">raw_h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">H_init</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">logit</span><span class="p">()</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="k">if</span> <span class="n">learnable_H</span><span class="p">:</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">raw_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">raw_h</span><span class="p">)</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;raw_h&quot;</span><span class="p">,</span> <span class="n">raw_h</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">H</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Current Hurst parameter value, constrained to (0.01, 0.99).&quot;&quot;&quot;</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_h</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.98</span> <span class="o">+</span> <span class="mf">0.01</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;davies_harte&quot;</span><span class="p">):</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Integrate the fSDE from initial conditions.</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">            x0: Initial state tensor of shape ``(batch, state_size)``.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">            n_steps: Number of integration steps.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">            method: fGn generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">            Trajectory tensor of shape ``(batch, n_steps+1, state_size)``.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">        Raises:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">            ValueError: If $H &lt; 0.5$ (rough regime not yet supported).</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="c1"># Validate H</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>        <span class="n">h_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="k">if</span> <span class="n">h_curr</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>             <span class="c1"># Euler-Maruyama unstable for H &lt; 0.5</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>                <span class="s2">&quot;Standard Euler-Maruyama solvers are mathematically unstable for H &lt; 0.5 &quot;</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>                <span class="s2">&quot;(Rough paths). Please use H &gt;= 0.5 or wait for stable release (Rough Signatures).&quot;</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>            <span class="p">)</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>            <span class="k">pass</span> 
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_max</span> <span class="o">/</span> <span class="n">n_steps</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="c1"># 2. Generate Noise</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="c1"># use Torch ops for H gradient to flow</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="n">fgn</span> <span class="o">=</span> <span class="n">generate_davies_harte</span><span class="p">(</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>            <span class="n">n_steps</span><span class="p">,</span> <span class="n">h_curr</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_size</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="p">)</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="c1"># 3. Scale Noise: fGn ~ N(0, 1) -&gt; N(0, dt^(2H))</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>        <span class="n">noise_increments</span> <span class="o">=</span> <span class="n">fgn</span> <span class="o">*</span> <span class="p">(</span><span class="n">dt</span> <span class="o">**</span> <span class="n">h_curr</span><span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>        <span class="c1"># 4. Integrate</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="n">xt</span> <span class="o">=</span> <span class="n">x0</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="c1">#eventual optimization: use jit or vectorized ops</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>            <span class="n">drift</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drift_net</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="n">diffusion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">diffusion_net</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="c1"># SDE: dX = mu*dt + sigma*dB</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="c1"># Using ito interpretation</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>            <span class="n">noise</span> <span class="o">=</span> <span class="n">diffusion</span> <span class="o">*</span> <span class="n">noise_increments</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>            <span class="n">xt</span> <span class="o">=</span> <span class="n">xt</span> <span class="o">+</span> <span class="n">drift</span> <span class="o">+</span> <span class="n">noise</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>            <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">trajectory</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="torchfbm.sde.NeuralFSDE.H" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">H</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Current Hurst parameter value, constrained to (0.01, 0.99).</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="torchfbm.sde.NeuralFSDE.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;davies_harte&#39;</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Integrate the fSDE from initial conditions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x0</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial state tensor of shape <code>(batch, state_size)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_steps</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of integration steps.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>fGn generation method ('davies_harte' or 'cholesky').</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Trajectory tensor of shape <code>(batch, n_steps+1, state_size)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <span class="arithmatex">\(H &lt; 0.5\)</span> (rough regime not yet supported).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/sde.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;davies_harte&quot;</span><span class="p">):</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Integrate the fSDE from initial conditions.</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">        x0: Initial state tensor of shape ``(batch, state_size)``.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        n_steps: Number of integration steps.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">        method: fGn generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">        Trajectory tensor of shape ``(batch, n_steps+1, state_size)``.</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">        ValueError: If $H &lt; 0.5$ (rough regime not yet supported).</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="c1"># Validate H</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="n">h_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="k">if</span> <span class="n">h_curr</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>         <span class="c1"># Euler-Maruyama unstable for H &lt; 0.5</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>            <span class="s2">&quot;Standard Euler-Maruyama solvers are mathematically unstable for H &lt; 0.5 &quot;</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>            <span class="s2">&quot;(Rough paths). Please use H &gt;= 0.5 or wait for stable release (Rough Signatures).&quot;</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="p">)</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="k">pass</span> 
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>    <span class="n">dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_max</span> <span class="o">/</span> <span class="n">n_steps</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="c1"># 2. Generate Noise</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="c1"># use Torch ops for H gradient to flow</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="n">fgn</span> <span class="o">=</span> <span class="n">generate_davies_harte</span><span class="p">(</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="n">n_steps</span><span class="p">,</span> <span class="n">h_curr</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_size</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="p">)</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="c1"># 3. Scale Noise: fGn ~ N(0, 1) -&gt; N(0, dt^(2H))</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="n">noise_increments</span> <span class="o">=</span> <span class="n">fgn</span> <span class="o">*</span> <span class="p">(</span><span class="n">dt</span> <span class="o">**</span> <span class="n">h_curr</span><span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="c1"># 4. Integrate</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="n">xt</span> <span class="o">=</span> <span class="n">x0</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>    <span class="c1">#eventual optimization: use jit or vectorized ops</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="n">drift</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drift_net</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>        <span class="n">diffusion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">diffusion_net</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="c1"># SDE: dX = mu*dt + sigma*dB</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="c1"># Using ito interpretation</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="n">noise</span> <span class="o">=</span> <span class="n">diffusion</span> <span class="o">*</span> <span class="n">noise_increments</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="n">xt</span> <span class="o">=</span> <span class="n">xt</span> <span class="o">+</span> <span class="n">drift</span> <span class="o">+</span> <span class="n">noise</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">trajectory</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><hr />
<h2 id="loss-functions">Loss Functions</h2>
<p>Loss functions for enforcing fractal properties.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.loss" class="doc doc-heading">
            <code>torchfbm.loss</code>


</h2>

    <div class="doc doc-contents first">

        <p>Loss functions for enforcing fractional properties.</p>
<p>This module provides regularization losses that encourage neural network
outputs to exhibit specific fractional Brownian motion properties.</p>


<details class="these-losses-are-useful-for" open>
  <summary>These losses are useful for</summary>
  <ul>
<li>Generative models that should produce fractal-like outputs</li>
<li>Time series forecasting with memory preservation</li>
<li>Physics-informed neural networks with scaling constraints</li>
</ul>
</details>

<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.loss import HurstRegularizationLoss, SpectralConsistencyLoss
hurst_loss = HurstRegularizationLoss(target_H=0.7)
spectral_loss = SpectralConsistencyLoss(target_beta=2.4)  # beta = 2H + 1</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="torchfbm.loss.HurstRegularizationLoss" class="doc doc-heading">
            <code>HurstRegularizationLoss</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Regularization loss penalizing deviation from target Hurst exponent.</p>
<p>Encourages generated time series to have a specific Hurst parameter
by adding a penalty term to the training objective.</p>
<p>The loss is computed as:</p>
<div class="arithmatex">\[\mathcal{L}_{Hurst} = \lambda (\hat{H}(x) - H_{target})^2\]</div>
<p>where <span class="arithmatex">\(\hat{H}(x)\)</span> is the estimated Hurst exponent of the input.</p>


<details class="usage-in-training" open>
  <summary>Usage in Training</summary>
  <p>Combine with task loss for multi-objective optimization:</p>
<blockquote>
<blockquote>
<blockquote>
<p>total_loss = mse_loss(pred, target) + 0.1 * hurst_reg(pred)</p>
</blockquote>
</blockquote>
</blockquote>
</details>

<details class="note" open>
  <summary>Note</summary>
  <p>The Hurst estimation uses R/S analysis, which may not be fully
differentiable. Consider using :class:<code>SpectralConsistencyLoss</code>
for smoother gradients.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>target_H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target Hurst exponent to encourage. Typically in (0, 1).</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>reg = HurstRegularizationLoss(target_H=0.7)
x = torch.randn(32, 100)  # Batch of sequences
loss = reg(x)  # Penalty for deviation from H=0.7</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/loss.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="k">class</span><span class="w"> </span><span class="nc">HurstRegularizationLoss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Regularization loss penalizing deviation from target Hurst exponent.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    Encourages generated time series to have a specific Hurst parameter</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    by adding a penalty term to the training objective.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    The loss is computed as:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    $$\\mathcal{L}_{Hurst} = \\lambda (\\hat{H}(x) - H_{target})^2$$</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    where $\\hat{H}(x)$ is the estimated Hurst exponent of the input.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    Usage in Training:</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        Combine with task loss for multi-objective optimization:</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        &gt;&gt;&gt; total_loss = mse_loss(pred, target) + 0.1 * hurst_reg(pred)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">        The Hurst estimation uses R/S analysis, which may not be fully</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">        differentiable. Consider using :class:`SpectralConsistencyLoss`</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        for smoother gradients.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        target_H: Target Hurst exponent to encourage. Typically in (0, 1).</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        &gt;&gt;&gt; reg = HurstRegularizationLoss(target_H=0.7)</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        &gt;&gt;&gt; x = torch.randn(32, 100)  # Batch of sequences</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        &gt;&gt;&gt; loss = reg(x)  # Penalty for deviation from H=0.7</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_H</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">target_H</span> <span class="o">=</span> <span class="n">target_H</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute Hurst regularization loss.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">            x: Input tensor of shape ``(batch, time)`` or ``(time,)``.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">            Scalar loss tensor.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="n">h_est</span> <span class="o">=</span> <span class="n">estimate_hurst</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="c1">#Use spectral consistency for more stable differentiation</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">h_est</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_H</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.loss.HurstRegularizationLoss.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Compute Hurst regularization loss.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor of shape <code>(batch, time)</code> or <code>(time,)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scalar loss tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/loss.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Hurst regularization loss.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        x: Input tensor of shape ``(batch, time)`` or ``(time,)``.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        Scalar loss tensor.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="n">h_est</span> <span class="o">=</span> <span class="n">estimate_hurst</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="c1">#Use spectral consistency for more stable differentiation</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">h_est</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_H</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="torchfbm.loss.SpectralConsistencyLoss" class="doc doc-heading">
            <code>SpectralConsistencyLoss</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Spectral loss for enforcing power-law scaling.</p>
<p>Penalizes deviations from the target spectral exponent <span class="arithmatex">\(\beta\)</span>,
where the power spectral density follows:</p>
<div class="arithmatex">\[S(f) \propto \frac{1}{f^\beta}\]</div>
<p>For fractional Brownian motion, <span class="arithmatex">\(\beta = 2H + 1\)</span>, so:
- <span class="arithmatex">\(H = 0.5\)</span> (Brownian): <span class="arithmatex">\(\beta = 2.0\)</span>
- <span class="arithmatex">\(H = 0.7\)</span> (Persistent): <span class="arithmatex">\(\beta = 2.4\)</span>
- <span class="arithmatex">\(H = 0.3\)</span> (Anti-persistent): <span class="arithmatex">\(\beta = 1.6\)</span></p>


<details class="features" open>
  <summary>Features</summary>
  <ul>
<li><strong>PSD smoothing</strong>: Reduces variance in spectral estimate</li>
<li><strong>Frequency masking</strong>: Ignores DC and Nyquist components</li>
<li><strong>Windowing</strong>: Hann window reduces spectral leakage</li>
<li><strong>Differentiable</strong>: Gradients flow through regression</li>
</ul>
</details>

<details class="algorithm" open>
  <summary>Algorithm</summary>
  <ol>
<li>Apply Hann window and compute FFT</li>
<li>Estimate power spectral density</li>
<li>Smooth PSD with average pooling</li>
<li>Mask to relevant frequency range</li>
<li>Linear regression in log-log space to estimate <span class="arithmatex">\(\beta\)</span></li>
<li>MSE loss against target <span class="arithmatex">\(\beta\)</span></li>
</ol>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>target_beta</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target spectral exponent. For fBm: <span class="arithmatex">\(\beta = 2H + 1\)</span>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>low_freq_cutoff</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Normalized frequency below which to ignore (avoids DC).</p>
              </div>
            </td>
            <td>
                  <code>0.02</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>high_freq_cutoff</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Normalized frequency above which to ignore (avoids noise).</p>
              </div>
            </td>
            <td>
                  <code>0.9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>smooth_kernel</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Kernel size for PSD smoothing.</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>loss_fn = SpectralConsistencyLoss(target_beta=2.4)  # H=0.7
x = fbm(1000, H=0.7, size=(32,))
loss = loss_fn(x)  # Should be small for correct H</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/loss.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="k">class</span><span class="w"> </span><span class="nc">SpectralConsistencyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Spectral loss for enforcing power-law scaling.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">    Penalizes deviations from the target spectral exponent $\\beta$,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">    where the power spectral density follows:</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">    $$S(f) \\propto \\frac{1}{f^\\beta}$$</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">    For fractional Brownian motion, $\\beta = 2H + 1$, so:</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">    - $H = 0.5$ (Brownian): $\\beta = 2.0$</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">    - $H = 0.7$ (Persistent): $\\beta = 2.4$</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    - $H = 0.3$ (Anti-persistent): $\\beta = 1.6$</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">    Features:</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        - **PSD smoothing**: Reduces variance in spectral estimate</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">        - **Frequency masking**: Ignores DC and Nyquist components</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">        - **Windowing**: Hann window reduces spectral leakage</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">        - **Differentiable**: Gradients flow through regression</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    Algorithm:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        1. Apply Hann window and compute FFT</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        2. Estimate power spectral density</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        3. Smooth PSD with average pooling</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        4. Mask to relevant frequency range</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        5. Linear regression in log-log space to estimate $\\beta$</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        6. MSE loss against target $\\beta$</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        target_beta: Target spectral exponent. For fBm: $\\beta = 2H + 1$.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        low_freq_cutoff: Normalized frequency below which to ignore (avoids DC).</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        high_freq_cutoff: Normalized frequency above which to ignore (avoids noise).</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        smooth_kernel: Kernel size for PSD smoothing.</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        &gt;&gt;&gt; loss_fn = SpectralConsistencyLoss(target_beta=2.4)  # H=0.7</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">        &gt;&gt;&gt; x = fbm(1000, H=0.7, size=(32,))</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        &gt;&gt;&gt; loss = loss_fn(x)  # Should be small for correct H</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="bp">self</span><span class="p">,</span> 
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="n">target_beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="n">low_freq_cutoff</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.02</span><span class="p">,</span> 
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="n">high_freq_cutoff</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> 
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="n">smooth_kernel</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>    <span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">target_beta</span> <span class="o">=</span> <span class="n">target_beta</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">low_freq_cutoff</span> <span class="o">=</span> <span class="n">low_freq_cutoff</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">high_freq_cutoff</span> <span class="o">=</span> <span class="n">high_freq_cutoff</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">smooth_kernel</span> <span class="o">=</span> <span class="n">smooth_kernel</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute spectral consistency loss.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">            x: Input tensor of shape ``(batch, channels, time)`` or ``(batch, time)``.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">            Scalar MSE loss between estimated and target beta.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="c1"># x shape: (Batch, Channels, Time) or (Batch, Time)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="c1"># 1. Compute PSD with Windowing (to reduce leakage)</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="c1"># Hann window prevents the &quot;cliff-edge&quot; effect at the ends of the sequence</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="n">window</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hann_window</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">periodic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>        <span class="n">fft</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">window</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="n">psd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">fft</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="c1"># 2. Smooth the PSD</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="c1"># Raw periodograms are too noisy for stable gradients. </span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="c1"># We apply a 1D average pool to smooth the spectral estimate.</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth_kernel</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>            <span class="n">psd</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool1d</span><span class="p">(</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>                <span class="n">psd</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">psd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> 
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">smooth_kernel</span><span class="p">,</span> 
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>                <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">smooth_kernel</span> <span class="o">//</span> <span class="mi">2</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">psd</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="c1"># 3. Frequency setup</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="n">freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftfreq</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="c1"># 4. Create Mask</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="c1"># Skip DC component and extreme high-frequency noise</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">freqs</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_freq_cutoff</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">freqs</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_freq_cutoff</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="c1"># Ensure at least some bins remain</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="n">log_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">freqs</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>        <span class="n">log_psd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">psd</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="c1"># 5. Batch Regression</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="c1"># We solve: log_psd = -beta * log_f + intercept</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="c1"># Formula for slope: beta = - Cov(log_f, log_psd) / Var(log_f)</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="n">mean_f</span> <span class="o">=</span> <span class="n">log_f</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="n">mean_psd</span> <span class="o">=</span> <span class="n">log_psd</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="n">diff_f</span> <span class="o">=</span> <span class="n">log_f</span> <span class="o">-</span> <span class="n">mean_f</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="n">diff_psd</span> <span class="o">=</span> <span class="n">log_psd</span> <span class="o">-</span> <span class="n">mean_psd</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="n">num</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff_f</span> <span class="o">*</span> <span class="n">diff_psd</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">den</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff_f</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="n">estimated_beta</span> <span class="o">=</span> <span class="o">-</span><span class="n">num</span> <span class="o">/</span> <span class="p">(</span><span class="n">den</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="c1"># 6. Penalize deviations from target</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">estimated_beta</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">estimated_beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_beta</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.loss.SpectralConsistencyLoss.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Compute spectral consistency loss.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor of shape <code>(batch, channels, time)</code> or <code>(batch, time)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scalar MSE loss between estimated and target beta.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/loss.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute spectral consistency loss.</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">        x: Input tensor of shape ``(batch, channels, time)`` or ``(batch, time)``.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        Scalar MSE loss between estimated and target beta.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="c1"># x shape: (Batch, Channels, Time) or (Batch, Time)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="c1"># 1. Compute PSD with Windowing (to reduce leakage)</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="c1"># Hann window prevents the &quot;cliff-edge&quot; effect at the ends of the sequence</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="n">window</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hann_window</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">periodic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="n">fft</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">window</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>    <span class="n">psd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">fft</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="c1"># 2. Smooth the PSD</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="c1"># Raw periodograms are too noisy for stable gradients. </span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="c1"># We apply a 1D average pool to smooth the spectral estimate.</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth_kernel</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="n">psd</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool1d</span><span class="p">(</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>            <span class="n">psd</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">psd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> 
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">smooth_kernel</span><span class="p">,</span> 
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">smooth_kernel</span> <span class="o">//</span> <span class="mi">2</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">psd</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>    <span class="c1"># 3. Frequency setup</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="n">freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftfreq</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="c1"># 4. Create Mask</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="c1"># Skip DC component and extreme high-frequency noise</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">freqs</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">low_freq_cutoff</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">freqs</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_freq_cutoff</span><span class="p">)</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="c1"># Ensure at least some bins remain</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">log_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">freqs</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">log_psd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">psd</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="c1"># 5. Batch Regression</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="c1"># We solve: log_psd = -beta * log_f + intercept</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>    <span class="c1"># Formula for slope: beta = - Cov(log_f, log_psd) / Var(log_f)</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="n">mean_f</span> <span class="o">=</span> <span class="n">log_f</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="n">mean_psd</span> <span class="o">=</span> <span class="n">log_psd</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="n">diff_f</span> <span class="o">=</span> <span class="n">log_f</span> <span class="o">-</span> <span class="n">mean_f</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="n">diff_psd</span> <span class="o">=</span> <span class="n">log_psd</span> <span class="o">-</span> <span class="n">mean_psd</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">num</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff_f</span> <span class="o">*</span> <span class="n">diff_psd</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="n">den</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff_f</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="n">estimated_beta</span> <span class="o">=</span> <span class="o">-</span><span class="n">num</span> <span class="o">/</span> <span class="p">(</span><span class="n">den</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="c1"># 6. Penalize deviations from target</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">estimated_beta</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">estimated_beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_beta</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><hr />
<h2 id="schedulers">Schedulers</h2>
<p>Hurst parameter scheduling for diffusion models.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.schedulers" class="doc doc-heading">
            <code>torchfbm.schedulers</code>


</h2>

    <div class="doc doc-contents first">

        <p>Hurst parameter schedules for diffusion models.</p>
<p>This module provides annealing schedules for the Hurst parameter,
useful in fractional diffusion models where the roughness of the
noise varies across sampling steps.</p>
<p>Inspired by noise scheduling in denoising diffusion models
(Ho, Jain &amp; Abbeel, 2020).</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.schedulers import get_hurst_schedule</p>
<h3 id="torchfbm.schedulers--smooth-start-rough-end">Smooth start, rough end</h3>
<p>schedule = get_hurst_schedule(100, start_H=0.7, end_H=0.3, type='cosine')</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.schedulers.get_hurst_schedule" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_hurst_schedule</span><span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">start_H</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">end_H</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Generate a schedule of Hurst parameters for diffusion sampling.</p>
<p>Creates an annealing schedule that varies the Hurst parameter across
diffusion time steps. This allows for adaptive noise roughness during
the generation process.</p>


<details class="schedule-types" open>
  <summary>Schedule Types</summary>
  <ul>
<li>
<p><strong>linear</strong>: Uniform interpolation between start and end values</p>
<div class="arithmatex">\[H_t = start_H + \frac{t}{T}(end_H - start_H)\]</div>
</li>
<li>
<p><strong>cosine</strong>: Smooth cosine annealing (slower changes at endpoints)</p>
<div class="arithmatex">\[H_t = end_H + \frac{1}{2}(start_H - end_H)(1 + \cos(\frac{\pi t}{T}))\]</div>
</li>
</ul>
</details>

<details class="applications" open>
  <summary>Applications</summary>
  <ul>
<li><strong>Diffusion models</strong>: Varying noise roughness during denoising</li>
<li><strong>Curriculum learning</strong>: Gradually changing correlation structure</li>
<li><strong>Annealing</strong>: Smooth transition between memory regimes</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n_steps</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of steps in the schedule.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>start_H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial Hurst parameter value.</p>
              </div>
            </td>
            <td>
                  <code>0.3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>end_H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Final Hurst parameter value.</p>
              </div>
            </td>
            <td>
                  <code>0.7</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>type</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Schedule type, either 'linear' or 'cosine'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;linear&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tensor of shape <code>(n_steps,)</code> with Hurst values.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.schedulers.get_hurst_schedule--linear-schedule-from-rough-to-smooth">Linear schedule from rough to smooth</h4>
<p>h_linear = get_hurst_schedule(100, start_H=0.3, end_H=0.7, type='linear')
h_linear[0], h_linear[-1]  # 0.3, 0.7</p>
<h4 id="torchfbm.schedulers.get_hurst_schedule--cosine-schedule-slower-at-endpoints">Cosine schedule (slower at endpoints)</h4>
<p>h_cosine = get_hurst_schedule(100, start_H=0.3, end_H=0.7, type='cosine')</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/schedulers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_hurst_schedule</span><span class="p">(</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">start_H</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">end_H</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="p">):</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate a schedule of Hurst parameters for diffusion sampling.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    Creates an annealing schedule that varies the Hurst parameter across</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    diffusion time steps. This allows for adaptive noise roughness during</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    the generation process.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    Schedule Types:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        - **linear**: Uniform interpolation between start and end values</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">            $$H_t = start_H + \\frac{t}{T}(end_H - start_H)$$</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        - **cosine**: Smooth cosine annealing (slower changes at endpoints)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">            $$H_t = end_H + \\frac{1}{2}(start_H - end_H)(1 + \\cos(\\frac{\\pi t}{T}))$$</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    Applications:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        - **Diffusion models**: Varying noise roughness during denoising</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">        - **Curriculum learning**: Gradually changing correlation structure</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        - **Annealing**: Smooth transition between memory regimes</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        n_steps: Total number of steps in the schedule.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">        start_H: Initial Hurst parameter value.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        end_H: Final Hurst parameter value.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        type: Schedule type, either &#39;linear&#39; or &#39;cosine&#39;.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        Tensor of shape ``(n_steps,)`` with Hurst values.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        &gt;&gt;&gt; # Linear schedule from rough to smooth</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        &gt;&gt;&gt; h_linear = get_hurst_schedule(100, start_H=0.3, end_H=0.7, type=&#39;linear&#39;)</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        &gt;&gt;&gt; h_linear[0], h_linear[-1]  # 0.3, 0.7</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        &gt;&gt;&gt; # Cosine schedule (slower at endpoints)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        &gt;&gt;&gt; h_cosine = get_hurst_schedule(100, start_H=0.3, end_H=0.7, type=&#39;cosine&#39;)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start_H</span><span class="p">,</span> <span class="n">end_H</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="n">steps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>        <span class="k">return</span> <span class="n">end_H</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">start_H</span> <span class="o">-</span> <span class="n">end_H</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>            <span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">steps</span> <span class="o">/</span> <span class="n">n_steps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="augmentations">Augmentations</h2>
<p>Data augmentation with fractional noise.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.augmentations" class="doc doc-heading">
            <code>torchfbm.augmentations</code>


</h2>

    <div class="doc doc-contents first">

        <p>Data augmentation with fractional Gaussian noise.</p>
<p>This module provides augmentation techniques that add correlated noise
to training data, helping models become robust to specific correlation
structures in input data.</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.augmentations import FractionalNoiseAugmentation
augment = FractionalNoiseAugmentation(H=0.7, sigma=0.01)
x_augmented = augment(x)</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="torchfbm.augmentations.FractionalNoiseAugmentation" class="doc doc-heading">
            <code>FractionalNoiseAugmentation</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Data augmentation by adding fractional Gaussian noise.</p>
<p>Adds fGn with specified Hurst parameter to training samples,
helping models become robust to different correlation structures.</p>
<p>The augmentation adds noise scaled by sigma:</p>
<div class="arithmatex">\[x_{aug} = x + \sigma \cdot fGn(H)\]</div>


<details class="use-cases" open>
  <summary>Use Cases</summary>
  <ul>
<li><strong>H &gt; 0.5 (persistent)</strong>: Robustness to trending patterns</li>
<li><strong>H &lt; 0.5 (anti-persistent)</strong>: Robustness to mean-reverting noise</li>
<li><strong>H = 0.5</strong>: Equivalent to standard Gaussian noise augmentation</li>
</ul>
</details>        <p>The augmentation is only applied during training with probability <code>p</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter for the fGn. Controls correlation structure.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Noise amplitude scaling factor.</p>
              </div>
            </td>
            <td>
                  <code>0.01</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>p</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Probability of applying the augmentation (per sample).</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.augmentations.FractionalNoiseAugmentation--make-model-robust-to-trending-noise">Make model robust to trending noise</h4>
<p>augment = FractionalNoiseAugmentation(H=0.7, sigma=0.01, p=0.5)
model = nn.Sequential(augment, nn.Linear(100, 10))</p>
<h4 id="torchfbm.augmentations.FractionalNoiseAugmentation--during-training-50-of-samples-get-fgn-added">During training, 50% of samples get fGn added</h4>
<p>model.train()
y = model(x)  # Augmentation active</p>
<h4 id="torchfbm.augmentations.FractionalNoiseAugmentation--during-eval-no-augmentation">During eval, no augmentation</h4>
<p>model.eval()
y = model(x)  # No noise added</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/augmentations.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="k">class</span><span class="w"> </span><span class="nc">FractionalNoiseAugmentation</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Data augmentation by adding fractional Gaussian noise.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    Adds fGn with specified Hurst parameter to training samples,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    helping models become robust to different correlation structures.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    The augmentation adds noise scaled by sigma:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    $$x_{aug} = x + \\sigma \\cdot fGn(H)$$</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    Use Cases:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        - **H &gt; 0.5 (persistent)**: Robustness to trending patterns</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        - **H &lt; 0.5 (anti-persistent)**: Robustness to mean-reverting noise</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">        - **H = 0.5**: Equivalent to standard Gaussian noise augmentation</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    The augmentation is only applied during training with probability ``p``.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">        H: Hurst parameter for the fGn. Controls correlation structure.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        sigma: Noise amplitude scaling factor.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">        p: Probability of applying the augmentation (per sample).</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        &gt;&gt;&gt; # Make model robust to trending noise</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">        &gt;&gt;&gt; augment = FractionalNoiseAugmentation(H=0.7, sigma=0.01, p=0.5)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">        &gt;&gt;&gt; model = nn.Sequential(augment, nn.Linear(100, 10))</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        &gt;&gt;&gt; </span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">        &gt;&gt;&gt; # During training, 50% of samples get fGn added</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        &gt;&gt;&gt; model.train()</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        &gt;&gt;&gt; y = model(x)  # Augmentation active</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        &gt;&gt;&gt; </span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">        &gt;&gt;&gt; # During eval, no augmentation</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        &gt;&gt;&gt; model.eval()</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        &gt;&gt;&gt; y = model(x)  # No noise added</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">H</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">H</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply fractional noise augmentation.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">            x: Input tensor. Noise is added along the last dimension.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">            Augmented tensor (during training with probability p),</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">            or unchanged input (during eval or with probability 1-p).</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>            <span class="n">noise</span> <span class="o">=</span> <span class="n">generate_davies_harte</span><span class="p">(</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>                <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">noise</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.augmentations.FractionalNoiseAugmentation.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Apply fractional noise augmentation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor. Noise is added along the last dimension.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Augmented tensor (during training with probability p),</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>or unchanged input (during eval or with probability 1-p).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/augmentations.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply fractional noise augmentation.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        x: Input tensor. Noise is added along the last dimension.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        Augmented tensor (during training with probability p),</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        or unchanged input (during eval or with probability 1-p).</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="n">noise</span> <span class="o">=</span> <span class="n">generate_davies_harte</span><span class="p">(</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>            <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">noise</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><hr />
<h2 id="online">Online</h2>
<p>Streaming/online generation of fGn.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.online" class="doc doc-heading">
            <code>torchfbm.online</code>


</h2>

    <div class="doc doc-contents first">

        <p>Online (streaming) fractional Gaussian noise generation.</p>
<p>This module provides incremental generation of fGn samples, useful when
the sequence length is not known in advance or when memory constraints
prevent batch generation.</p>
<p>Based on the incremental Cholesky update approach from Dietrich &amp; Newsam (1997).</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.online import CachedFGNGenerator
gen = CachedFGNGenerator(H=0.7)
samples = [gen.step() for _ in range(100)]</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="torchfbm.online.CachedFGNGenerator" class="doc doc-heading">
            <code>CachedFGNGenerator</code>


</h3>


    <div class="doc doc-contents ">



        <p>Online fractional Gaussian noise generator with incremental Cholesky updates.</p>
<p>Based on Dietrich &amp; Newsam (1997).</p>
<p>Generates exact fGn samples one at a time, maintaining the correct
correlation structure by incrementally updating the Cholesky factorization.</p>


<details class="algorithm" open>
  <summary>Algorithm</summary>
  <p>At step <span class="arithmatex">\(n\)</span>, we have the covariance matrix <span class="arithmatex">\(\Sigma_n\)</span> and its
Cholesky factor <span class="arithmatex">\(L_n\)</span> such that <span class="arithmatex">\(\Sigma_n = L_n L_n^T\)</span>.</p>
<p>To add a new sample:
1. Compute the new covariance row <span class="arithmatex">\(\mathbf{v} = Cov(X_{n+1}, X_1, ..., X_n)\)</span>
2. Solve <span class="arithmatex">\(L_n \mathbf{w} = \mathbf{v}\)</span> for <span class="arithmatex">\(\mathbf{w}\)</span>
3. Compute <span class="arithmatex">\(\delta = \sqrt{\gamma(0) - \|\mathbf{w}\|^2}\)</span>
4. Generate <span class="arithmatex">\(X_{n+1} = \mathbf{w}^T \mathbf{Z} + \delta z_{new}\)</span>
5. Extend <span class="arithmatex">\(L_{n+1}\)</span> with the new row</p>
</details>

<details class="complexity" open>
  <summary>Complexity</summary>
  <ul>
<li>Per step: <span class="arithmatex">\(O(n)\)</span> for solve and update</li>
<li>Total for <span class="arithmatex">\(N\)</span> steps: <span class="arithmatex">\(O(N^2)\)</span></li>
<li>Memory: <span class="arithmatex">\(O(N^2)\)</span> for Cholesky factor</li>
</ul>
</details>

<details class="note" open>
  <summary>Note</summary>
  <p>For batch generation where the full length is known, use
:func:<code>generate_cholesky</code> or :func:<code>generate_davies_harte</code> instead.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter in (0, 1).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computation device ('cpu' or 'cuda').</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for tensors.</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.float32">float32</span></code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="torchfbm.online.CachedFGNGenerator.n">n</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current number of generated samples.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="torchfbm.online.CachedFGNGenerator.H">H</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>gen = CachedFGNGenerator(H=0.7, device='cpu')</p>
<h4 id="torchfbm.online.CachedFGNGenerator--generate-samples-one-at-a-time">Generate samples one at a time</h4>
<p>for _ in range(100):
...     sample = gen.step()
...     process_sample(sample)</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/online.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="k">class</span><span class="w"> </span><span class="nc">CachedFGNGenerator</span><span class="p">:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Online fractional Gaussian noise generator with incremental Cholesky updates.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    Based on Dietrich &amp; Newsam (1997).</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    Generates exact fGn samples one at a time, maintaining the correct</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    correlation structure by incrementally updating the Cholesky factorization.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    Algorithm:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        At step $n$, we have the covariance matrix $\\Sigma_n$ and its</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        Cholesky factor $L_n$ such that $\\Sigma_n = L_n L_n^T$.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        To add a new sample:</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        1. Compute the new covariance row $\\mathbf{v} = Cov(X_{n+1}, X_1, ..., X_n)$</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        2. Solve $L_n \\mathbf{w} = \\mathbf{v}$ for $\\mathbf{w}$</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        3. Compute $\\delta = \\sqrt{\\gamma(0) - \\|\\mathbf{w}\\|^2}$</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">        4. Generate $X_{n+1} = \\mathbf{w}^T \\mathbf{Z} + \\delta z_{new}$</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        5. Extend $L_{n+1}$ with the new row</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    Complexity:</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">        - Per step: $O(n)$ for solve and update</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        - Total for $N$ steps: $O(N^2)$</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">        - Memory: $O(N^2)$ for Cholesky factor</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    Note:</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">        For batch generation where the full length is known, use</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        :func:`generate_cholesky` or :func:`generate_davies_harte` instead.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">        H: Hurst parameter in (0, 1).</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        device: Computation device (&#39;cpu&#39; or &#39;cuda&#39;).</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        dtype: Data type for tensors.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    Attributes:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        n: Current number of generated samples.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        H: Hurst parameter.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        &gt;&gt;&gt; gen = CachedFGNGenerator(H=0.7, device=&#39;cpu&#39;)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        &gt;&gt;&gt; # Generate samples one at a time</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        &gt;&gt;&gt; for _ in range(100):</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        ...     sample = gen.step()</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        ...     process_sample(sample)</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">H</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">z_history</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate the next sample in the fGn sequence.</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        Each call generates a single correlated sample that maintains</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">        the correct fGn covariance structure with all previous samples.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">            Scalar tensor containing the next fGn value.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">        Example:</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">            &gt;&gt;&gt; gen = CachedFGNGenerator(H=0.7)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">            &gt;&gt;&gt; x1 = gen.step()  # First sample</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">            &gt;&gt;&gt; x2 = gen.step()  # Second sample (correlated with x1)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">new_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="k">if</span> <span class="n">new_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>            <span class="c1"># Initialize first point</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>            <span class="n">val</span> <span class="o">=</span> <span class="n">z</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">z_history</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">z_history</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>            <span class="c1"># Incremental Cholesky update</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>            <span class="n">full_gamma</span> <span class="o">=</span> <span class="n">_autocovariance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="n">new_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>            <span class="n">v</span> <span class="o">=</span> <span class="n">full_gamma</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>            <span class="n">c</span> <span class="o">=</span> <span class="n">full_gamma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>            <span class="c1"># Solve L * w = v via forward substitution</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>            <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>            <span class="n">w_flat</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>            <span class="n">w_norm_sq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w_flat</span><span class="p">,</span> <span class="n">w_flat</span><span class="p">)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>            <span class="n">delta_sq</span> <span class="o">=</span> <span class="n">c</span> <span class="o">-</span> <span class="n">w_norm_sq</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>            <span class="n">delta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">delta_sq</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>            <span class="c1"># Generate correlated sample: X = w^T Z + delta * z_new</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w_flat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_history</span><span class="p">)</span> <span class="o">+</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">z</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">z_history</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">z_history</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>            <span class="c1"># Extend Cholesky factor</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>            <span class="n">zeros_col</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="n">L_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">zeros_col</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>            <span class="n">bottom_row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">w_flat</span><span class="p">,</span> <span class="n">delta</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">L_padded</span><span class="p">,</span> <span class="n">bottom_row</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="k">return</span> <span class="n">val</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.online.CachedFGNGenerator.step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">step</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Generate the next sample in the fGn sequence.</p>
<p>Each call generates a single correlated sample that maintains
the correct fGn covariance structure with all previous samples.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Scalar tensor containing the next fGn value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>gen = CachedFGNGenerator(H=0.7)
x1 = gen.step()  # First sample
x2 = gen.step()  # Second sample (correlated with x1)</p>
</blockquote>
</blockquote>
</blockquote>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/online.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate the next sample in the fGn sequence.</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">    Each call generates a single correlated sample that maintains</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">    the correct fGn covariance structure with all previous samples.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        Scalar tensor containing the next fGn value.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">        &gt;&gt;&gt; gen = CachedFGNGenerator(H=0.7)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        &gt;&gt;&gt; x1 = gen.step()  # First sample</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">        &gt;&gt;&gt; x2 = gen.step()  # Second sample (correlated with x1)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="n">new_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="k">if</span> <span class="n">new_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="c1"># Initialize first point</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="n">val</span> <span class="o">=</span> <span class="n">z</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">z_history</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">z_history</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="c1"># Incremental Cholesky update</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="n">full_gamma</span> <span class="o">=</span> <span class="n">_autocovariance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="n">new_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">full_gamma</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="n">c</span> <span class="o">=</span> <span class="n">full_gamma</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="c1"># Solve L * w = v via forward substitution</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">w_flat</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">w_norm_sq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w_flat</span><span class="p">,</span> <span class="n">w_flat</span><span class="p">)</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="n">delta_sq</span> <span class="o">=</span> <span class="n">c</span> <span class="o">-</span> <span class="n">w_norm_sq</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="n">delta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">delta_sq</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="c1"># Generate correlated sample: X = w^T Z + delta * z_new</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w_flat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_history</span><span class="p">)</span> <span class="o">+</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">z</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">z_history</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">z_history</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="c1"># Extend Cholesky factor</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="n">zeros_col</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="n">L_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">zeros_col</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="n">bottom_row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">w_flat</span><span class="p">,</span> <span class="n">delta</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">L_padded</span><span class="p">,</span> <span class="n">bottom_row</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)])</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="k">return</span> <span class="n">val</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><hr />
<h2 id="reinforcement-learning">Reinforcement Learning</h2>
<p>Action noise for RL exploration.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.rl" class="doc doc-heading">
            <code>torchfbm.rl</code>


</h2>

    <div class="doc doc-contents first">

        <p>Fractional noise for reinforcement learning exploration.</p>
<p>This module provides action noise generators using fractional Gaussian noise,
enabling correlated exploration strategies in RL algorithms.</p>


<details class="the-use-of-fgn-instead-of-white-noise-allows-for" open>
  <summary>The use of fGn instead of white noise allows for</summary>
  <ul>
<li>Smoother exploration trajectories (H &gt; 0.5)</li>
<li>More thorough local exploration (H &lt; 0.5)</li>
<li>Tunable temporal correlation in action perturbations</li>
</ul>
</details>        <p>Compatible with Stable Baselines3 and similar RL frameworks.</p>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>from torchfbm.rl import FBMActionNoise
noise = FBMActionNoise(mean=0, sigma=0.1, H=0.7)
action = policy(state) + noise()</p>
</blockquote>
</blockquote>
</blockquote>
</details>









<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="torchfbm.rl.FBMActionNoise" class="doc doc-heading">
            <code>FBMActionNoise</code>


</h3>


    <div class="doc doc-contents ">



        <p>Fractional Gaussian noise for RL action space exploration.</p>
<p>Generates temporally correlated noise for action exploration, providing
smoother or rougher perturbations depending on the Hurst parameter.</p>
<p>Inspired by Ornstein-Uhlenbeck noise commonly used in DDPG, but with
controllable long-range dependence.</p>


<details class="properties-by-hurst-parameter" open>
  <summary>Properties by Hurst Parameter</summary>
  <ul>
<li><strong>H &gt; 0.5 (persistent)</strong>: Smooth, trending exploration. Actions
  tend to continue in the same direction, good for momentum-based tasks.</li>
<li><strong>H = 0.5</strong>: Standard Gaussian noise (memoryless).</li>
<li><strong>H &lt; 0.5 (anti-persistent)</strong>: Rough, oscillating exploration.
  Actions frequently reverse, good for thorough local search.</li>
</ul>
</details>

<details class="implementation" open>
  <summary>Implementation</summary>
  <p>Pre-generates a buffer of fGn samples for efficiency. When the buffer
is exhausted, a new batch is generated automatically.</p>
</details>

<details class="compatibility" open>
  <summary>Compatibility</summary>
  <ul>
<li><strong>return_numpy=True</strong>: Compatible with Stable Baselines3</li>
<li><strong>return_numpy=False</strong>: Returns PyTorch tensors (for custom implementations)</li>
</ul>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mean</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mean of the noise distribution.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Standard deviation scaling factor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>H</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Hurst parameter in (0, 1). Controls temporal correlation.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Shape of noise samples (action dimensions).</p>
              </div>
            </td>
            <td>
                  <code>(1,)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>buffer_size</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of pre-generated samples.</p>
              </div>
            </td>
            <td>
                  <code>10000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generation method ('davies_harte' or 'cholesky').</p>
              </div>
            </td>
            <td>
                  <code>&#39;davies_harte&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Computation device for tensor generation.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_numpy</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, returns NumPy arrays (SB3 compatible).</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<h4 id="torchfbm.rl.FBMActionNoise--for-stable-baselines3">For Stable Baselines3</h4>
<p>noise = FBMActionNoise(
...     mean=np.zeros(action_dim),
...     sigma=0.1,
...     H=0.7,
...     return_numpy=True
... )
model = DDPG("MlpPolicy", env, action_noise=noise)</p>
<h4 id="torchfbm.rl.FBMActionNoise--for-custom-pytorch-rl">For custom PyTorch RL</h4>
<p>noise = FBMActionNoise(
...     mean=0, sigma=0.1, H=0.6, device='cuda'
... )
action = policy(state) + noise()</p>
</blockquote>
</blockquote>
</blockquote>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>torchfbm/rl.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="k">class</span><span class="w"> </span><span class="nc">FBMActionNoise</span><span class="p">:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fractional Gaussian noise for RL action space exploration.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    Generates temporally correlated noise for action exploration, providing</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    smoother or rougher perturbations depending on the Hurst parameter.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    Inspired by Ornstein-Uhlenbeck noise commonly used in DDPG, but with</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    controllable long-range dependence.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    Properties by Hurst Parameter:</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        - **H &gt; 0.5 (persistent)**: Smooth, trending exploration. Actions</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">          tend to continue in the same direction, good for momentum-based tasks.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        - **H = 0.5**: Standard Gaussian noise (memoryless).</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">        - **H &lt; 0.5 (anti-persistent)**: Rough, oscillating exploration.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">          Actions frequently reverse, good for thorough local search.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    Implementation:</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">        Pre-generates a buffer of fGn samples for efficiency. When the buffer</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">        is exhausted, a new batch is generated automatically.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">    Compatibility:</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">        - **return_numpy=True**: Compatible with Stable Baselines3</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        - **return_numpy=False**: Returns PyTorch tensors (for custom implementations)</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        mean: Mean of the noise distribution.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        sigma: Standard deviation scaling factor.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        H: Hurst parameter in (0, 1). Controls temporal correlation.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        size: Shape of noise samples (action dimensions).</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        buffer_size: Number of pre-generated samples.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        method: Generation method (&#39;davies_harte&#39; or &#39;cholesky&#39;).</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        device: Computation device for tensor generation.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        return_numpy: If True, returns NumPy arrays (SB3 compatible).</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    Example:</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        &gt;&gt;&gt; # For Stable Baselines3</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        &gt;&gt;&gt; noise = FBMActionNoise(</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        ...     mean=np.zeros(action_dim),</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        ...     sigma=0.1,</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        ...     H=0.7,</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        ...     return_numpy=True</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        &gt;&gt;&gt; model = DDPG(&quot;MlpPolicy&quot;, env, action_noise=noise)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        &gt;&gt;&gt; # For custom PyTorch RL</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        &gt;&gt;&gt; noise = FBMActionNoise(</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        ...     mean=0, sigma=0.1, H=0.6, device=&#39;cuda&#39;</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        ... )</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        &gt;&gt;&gt; action = policy(state) + noise()</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="n">mean</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="n">sigma</span><span class="p">,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="n">H</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;davies_harte&quot;</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="n">return_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="p">):</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">=</span> <span class="n">mean</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sigma</span> <span class="o">=</span> <span class="n">sigma</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_H</span> <span class="o">=</span> <span class="n">H</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_size</span> <span class="o">=</span> <span class="n">size</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_method</span> <span class="o">=</span> <span class="n">method</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_return_numpy</span> <span class="o">=</span> <span class="n">return_numpy</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Pre-generate a buffer of fGn samples.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        Called automatically during initialization and when the</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        buffer is exhausted during sampling.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_method</span> <span class="o">==</span> <span class="s2">&quot;cholesky&quot;</span><span class="p">:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>            <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_cholesky</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>            <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_davies_harte</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="n">fgn</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_return_numpy</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_noise_buffer</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>                    <span class="n">fgn</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>                <span class="p">)</span>  <span class="c1"># Convert to NumPy on CPU</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>            <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>                <span class="k">if</span> <span class="s2">&quot;Numpy is not available&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>                        <span class="s2">&quot;NumPy conversion requested but NumPy is not properly installed or has compatibility issues. &quot;</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>                        <span class="s2">&quot;Please install/upgrade numpy: pip install -U numpy&quot;</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>                    <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>                <span class="k">raise</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_noise_buffer</span> <span class="o">=</span> <span class="n">fgn</span>  <span class="c1"># Keep as Tensor on Device</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample noise for the current step.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">            Noise sample, either as NumPy array (if return_numpy=True)</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">            or PyTorch tensor.</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_size</span><span class="p">:</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_noise_buffer</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span><span class="p">]</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigma</span> <span class="o">*</span> <span class="n">noise</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_return_numpy</span><span class="p">:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>                <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>                    <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>                    <span class="k">if</span> <span class="s2">&quot;Numpy is not available&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>                        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>                            <span class="s2">&quot;NumPy conversion requested but NumPy is not properly installed or has compatibility issues. &quot;</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>                            <span class="s2">&quot;Please install/upgrade numpy: pip install -U numpy&quot;</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>                    <span class="k">raise</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>            <span class="c1"># If val is somehow numpy/float, cast to tensor</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>                <span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>            <span class="k">return</span> <span class="n">val</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;FBMActionNoise(mu=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_mu</span><span class="si">}</span><span class="s2">, sigma=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_sigma</span><span class="si">}</span><span class="s2">, H=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_H</span><span class="si">}</span><span class="s2">, numpy=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_return_numpy</span><span class="si">}</span><span class="s2">)&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="torchfbm.rl.FBMActionNoise.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Sample noise for the current step.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Noise sample, either as NumPy array (if return_numpy=True)</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>or PyTorch tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/rl.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample noise for the current step.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        Noise sample, either as NumPy array (if return_numpy=True)</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">        or PyTorch tensor.</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_size</span><span class="p">:</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_noise_buffer</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span><span class="p">]</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigma</span> <span class="o">*</span> <span class="n">noise</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_return_numpy</span><span class="p">:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>                <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>            <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>                <span class="k">if</span> <span class="s2">&quot;Numpy is not available&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>                    <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>                        <span class="s2">&quot;NumPy conversion requested but NumPy is not properly installed or has compatibility issues. &quot;</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>                        <span class="s2">&quot;Please install/upgrade numpy: pip install -U numpy&quot;</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>                    <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>                <span class="k">raise</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="c1"># If val is somehow numpy/float, cast to tensor</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>            <span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="k">return</span> <span class="n">val</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="torchfbm.rl.FBMActionNoise.reset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Pre-generate a buffer of fGn samples.</p>
<p>Called automatically during initialization and when the
buffer is exhausted during sampling.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/rl.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Pre-generate a buffer of fGn samples.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">    Called automatically during initialization and when the</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">    buffer is exhausted during sampling.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_method</span> <span class="o">==</span> <span class="s2">&quot;cholesky&quot;</span><span class="p">:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_cholesky</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">gen_func</span> <span class="o">=</span> <span class="n">generate_davies_harte</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="n">fgn</span> <span class="o">=</span> <span class="n">gen_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_H</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_return_numpy</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_noise_buffer</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>                <span class="n">fgn</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>            <span class="p">)</span>  <span class="c1"># Convert to NumPy on CPU</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>            <span class="k">if</span> <span class="s2">&quot;Numpy is not available&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>                    <span class="s2">&quot;NumPy conversion requested but NumPy is not properly installed or has compatibility issues. &quot;</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>                    <span class="s2">&quot;Please install/upgrade numpy: pip install -U numpy&quot;</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>            <span class="k">raise</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_noise_buffer</span> <span class="o">=</span> <span class="n">fgn</span>  <span class="c1"># Keep as Tensor on Device</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_step</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><h2 id="utilities">Utilities</h2>
<p>General utility functions for greater transparency and debugging.</p>


<div class="doc doc-object doc-module">



<h2 id="torchfbm.utils" class="doc doc-heading">
            <code>torchfbm.utils</code>


</h2>

    <div class="doc doc-contents first">










<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="torchfbm.utils.get_cholesky_factor" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_cholesky_factor</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">jitter</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Returns the Lower Triangular Matrix L such that Sigma = L @ L.T.
Useful for checking numerical stability or manual noise generation.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_cholesky_factor</span><span class="p">(</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="n">jitter</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    Returns the Lower Triangular Matrix L such that Sigma = L @ L.T.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    Useful for checking numerical stability or manual noise generation.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="n">sigma</span> <span class="o">=</span> <span class="n">get_fgn_covariance_matrix</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>    <span class="c1"># Add jitter for numerical stability (Conditioning)</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>    <span class="n">eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">sigma</span> <span class="o">+</span> <span class="n">jitter</span> <span class="o">*</span> <span class="n">eye</span><span class="p">)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="c1"># Fallback for higher jitter if matrix is nearly singular (common when H -&gt; 1.0)</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">sigma</span> <span class="o">+</span> <span class="n">jitter</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">eye</span><span class="p">)</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="k">return</span> <span class="n">L</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.utils.get_fgn_autocovariance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_fgn_autocovariance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Computes the first row of the Toeplitz covariance matrix for fGN.
gamma(k) = 0.5 * (|k+1|^2H - 2|k|^2H + |k-1|^2H)</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_fgn_autocovariance</span><span class="p">(</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    Computes the first row of the Toeplitz covariance matrix for fGN.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    gamma(k) = 0.5 * (|k+1|^2H - 2|k|^2H + |k-1|^2H)</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">H</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="torchfbm.utils.get_fgn_covariance_matrix" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_fgn_covariance_matrix</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Constructs the full symmetric Toeplitz Covariance Matrix for fGN.
Shape: (n, n)</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>torchfbm/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span>
<span class="normal"><a href="#__codelineno-0-26">26</a></span>
<span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_fgn_covariance_matrix</span><span class="p">(</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="n">H</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> 
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> 
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    Constructs the full symmetric Toeplitz Covariance Matrix for fGN.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    Shape: (n, n)</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>    <span class="c1"># 1. Get the first row (Autocovariance)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>    <span class="n">gamma</span> <span class="o">=</span> <span class="n">get_fgn_autocovariance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="c1"># 2. Use the Broadcasting Trick (No Loops)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>    <span class="c1"># This creates the indices |i - j| efficiently</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="n">lhs</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, n)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="n">rhs</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (n, 1)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="c1"># &quot;distance_matrix&quot; contains the lag k for every entry (i, j)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="n">distance_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">lhs</span> <span class="o">-</span> <span class="n">rhs</span><span class="p">)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="c1"># 3. Map gamma values to the matrix</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="c1"># PyTorch advanced indexing handles this instantly</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="k">return</span> <span class="n">gamma</span><span class="p">[</span><span class="n">distance_matrix</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["content.code.copy", "navigation.tabs", "navigation.sections"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>